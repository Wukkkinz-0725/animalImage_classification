{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wukkkinz-0725/animalImage_classification/blob/master/timm_models_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Wukkkinz-0725/animalImage_classification.git"
      ],
      "metadata": {
        "id": "p0Y0iPo8SjIX",
        "outputId": "a527dd26-a3e0-4da9-bd56-4665395b567e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p0Y0iPo8SjIX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'animalImage_classification'...\n",
            "remote: Enumerating objects: 18622, done.\u001b[K\n",
            "remote: Counting objects: 100% (18622/18622), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 18622 (delta 18572), reused 18581 (delta 18549), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18622/18622), 13.82 MiB | 20.88 MiB/s, done.\n",
            "Resolving deltas: 100% (18572/18572), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdj9jVAxjm6v",
        "outputId": "cd588192-9a1b-4a7d-81fe-3ec8d9b52389"
      },
      "id": "Cdj9jVAxjm6v",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "S_Q8363gRlIE"
      },
      "id": "S_Q8363gRlIE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./animalImage_classification/Released_Data')"
      ],
      "metadata": {
        "id": "DCG4pGJHR4QO"
      },
      "id": "DCG4pGJHR4QO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "ANiA5CLoC_E2"
      },
      "id": "ANiA5CLoC_E2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
      "metadata": {
        "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c"
      },
      "outputs": [],
      "source": [
        "# Create Dataset class for multilabel classification\n",
        "class MultiClassImageDataset(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.ann_df['image'][idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        super_idx = self.ann_df['superclass_index'][idx]\n",
        "        super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "        sub_idx = self.ann_df['subclass_index'][idx]\n",
        "        sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "class MultiClassImageTestDataset(Dataset):\n",
        "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): # Count files in img_dir\n",
        "        return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = str(idx) + '.jpg'\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_split(dataset, stratify_by='superclass_index'):\n",
        "    from torch.utils.data import Subset\n",
        "    # Extract labels for stratification\n",
        "    labels = np.array(dataset.ann_df[stratify_by])\n",
        "\n",
        "    # Perform stratified split\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1)\n",
        "    train_idx, val_idx = next(sss.split(np.zeros(len(labels)), labels))\n",
        "\n",
        "    # Create train and validation subsets\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "    return train_subset, val_subset"
      ],
      "metadata": {
        "id": "N_YUkjtNdSLj"
      },
      "id": "N_YUkjtNdSLj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_pil(tensor):\n",
        "    to_pil_image = transforms.ToPILImage()\n",
        "    pil_image = to_pil_image(tensor)\n",
        "    return pil_image"
      ],
      "metadata": {
        "id": "ztM74-BuruIO"
      },
      "id": "ztM74-BuruIO",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Load CIFAR-10 and CIFAR-100 datasets\n",
        "cifar10_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "cifar100_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Initialize counters and storage\n",
        "class_counts = {0: 0, 1: 0, 2: 0, 3: 0}  # bird, dog, reptile, novel\n",
        "filtered_images = []\n",
        "\n",
        "# Process CIFAR-10 (bird and dog)\n",
        "for image, label in cifar10_dataset:\n",
        "    if label in [2, 5]:  # CIFAR-10 labels for bird and dog\n",
        "        superclass = 0 if label == 2 else 1  # Convert to new superclass label\n",
        "        if class_counts[superclass] < 2000:\n",
        "            filtered_images.append((image, superclass, 87))  # subclass 87\n",
        "            class_counts[superclass] += 1\n",
        "\n",
        "for image, label in cifar10_dataset:\n",
        "    if label == 6:  # CIFAR-10 labels for bird and dog\n",
        "        if class_counts[2] < 1000:\n",
        "            filtered_images.append((image, 2, 87))  # subclass 87\n",
        "            class_counts[2] += 1\n",
        "\n",
        "\n",
        "# Process CIFAR-100 (reptile)\n",
        "for image, label in cifar100_dataset:\n",
        "    if 76 <= label <= 80:  # CIFAR-100 label for reptile\n",
        "        if class_counts[2] < 2000:\n",
        "            filtered_images.append((image, 2, 87))  # superclass 2, subclass 87\n",
        "            class_counts[2] += 1\n",
        "\n",
        "# Add novel images\n",
        "while class_counts[3] < 2000:\n",
        "    random_image, label = random.choice(cifar10_dataset)  # Randomly select an image\n",
        "    if label not in [2, 5, 6]:  # Exclude classes 2, 5, and 6\n",
        "        filtered_images.append((random_image, 3, 87))  # superclass 3, subclass 87\n",
        "        class_counts[3] += 1\n",
        "\n",
        "while class_counts[3] < 2000:\n",
        "    random_image, label = random.choice(cifar100_dataset)  # Randomly select an image\n",
        "    if label < 76 or label > 80:  # Exclude classes 2, 5, and 6\n",
        "        filtered_images.append((random_image, 3, 87))  # superclass 3, subclass 87\n",
        "        class_counts[3] += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBtFBx_1eZ8r",
        "outputId": "27196dda-0f38-4f51-bad9-24f8fe16d826"
      },
      "id": "DBtFBx_1eZ8r",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:10<00:00, 15911197.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:10<00:00, 15978960.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_filtered_image(idx):\n",
        "    image = filtered_images[idx]\n",
        "    print(image[1:])\n",
        "    tensor_to_pil(image[0])"
      ],
      "metadata": {
        "id": "JkPTt5xErL_i"
      },
      "id": "JkPTt5xErL_i",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read existing data from CSV file or create a new DataFrame if the file doesn't exist\n",
        "csv_file = 'train_data.csv'\n",
        "new_csv_file = 'train_data_v1.csv'\n",
        "existing_df = pd.read_csv(csv_file)\n",
        "DROP_IDX = [534, 589, 1013, 1231, 1274, 1501, 1827, 1922, 2191, 2195, 2197, 2548, 2575, 2578,\n",
        "2690, 3049, 3099, 3100, 3292, 3481, 3702, 3743, 4099, 4565, 4850, 4914, 5039, 5150,\n",
        "5222, 5350, 5557, 5726, 6037, 6262]\n",
        "existing_df.drop(DROP_IDX, axis=0)\n",
        "# Prepare CSV data for new images\n",
        "new_csv_data = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "for i, filtered_image in enumerate(filtered_images, start=6322):\n",
        "    file_name = f'{i}.jpg'\n",
        "    image_path = os.path.join('train_shuffle', file_name)\n",
        "    image = transforms.ToPILImage()(filtered_image[0])\n",
        "    image.save(image_path)\n",
        "    # Update CSV data\n",
        "    new_csv_data['image'].append(file_name)\n",
        "    new_csv_data['superclass_index'].append(filtered_image[1])\n",
        "    new_csv_data['subclass_index'].append(filtered_image[2])\n",
        "\n",
        "new_df = pd.DataFrame(new_csv_data)\n",
        "combined_df = existing_df.append(new_df, ignore_index=True)\n",
        "\n",
        "# Write the combined DataFrame to the CSV file\n",
        "combined_df.to_csv(new_csv_file, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErMMb3UYexxJ",
        "outputId": "45164bef-d1b6-4588-8e71-d20f93df194a"
      },
      "id": "ErMMb3UYexxJ",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-3c0448cc6feb>:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  combined_df = existing_df.append(new_df, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "MybZXEir47S2"
      },
      "id": "MybZXEir47S2"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e7398553-8842-4ad8-b348-767921a22482",
      "metadata": {
        "id": "e7398553-8842-4ad8-b348-767921a22482"
      },
      "outputs": [],
      "source": [
        "train_ann_df = pd.read_csv('train_data_v1.csv')\n",
        "super_map_df = pd.read_csv('superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
        "\n",
        "train_img_dir = 'train_shuffle'\n",
        "test_img_dir = 'test_shuffle'\n",
        "\n",
        "image_preprocessing = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
        "    transforms.RandomVerticalFlip(),    # vertical flip of the image\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),  # random color jitter\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # random translation\n",
        "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),  # random crop and resize\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # normalization\n",
        "])\n",
        "\n",
        "# Create train and val split\n",
        "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
        "train_dataset, val_dataset = stratified_split(train_dataset)\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=1,\n",
        "                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure it's read in RGB format\n",
        "    return image"
      ],
      "metadata": {
        "id": "PQEB38eRlGaY"
      },
      "id": "PQEB38eRlGaY",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainers"
      ],
      "metadata": {
        "id": "QQYpXee3q_gZ"
      },
      "id": "QQYpXee3q_gZ"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840",
      "metadata": {
        "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            loss += self.criterion(super_outputs, super_labels)\n",
        "            loss += self.criterion(sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                loss += self.criterion(super_outputs, super_labels)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                loss += self.criterion(sub_outputs, sub_labels)\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerSuper():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "        self.best_model_wts = None\n",
        "        self.best_accuracy = 0\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            loss += self.criterion(super_outputs, super_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        import copy\n",
        "        super_correct, total = 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                loss += self.criterion(super_outputs, super_labels)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "        if 100 * super_correct / total > self.best_accuracy:\n",
        "            self.best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            self.best_accuracy = 100 * super_correct / total\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions\n"
      ],
      "metadata": {
        "id": "0QAnsPv8o1N_"
      },
      "id": "0QAnsPv8o1N_",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerSub():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "        self.best_model_wts = None\n",
        "        self.best_accuracy = 0\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, sub_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            sub_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            loss += self.criterion(sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        import copy\n",
        "        sub_correct, total = 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, sub_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                sub_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                loss += self.criterion(sub_outputs, sub_labels)\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += sub_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "        if 100 * sub_correct / total > self.best_accuracy:\n",
        "            self.best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            self.best_accuracy = 100 * sub_correct / total\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                sub_outputs = self.model(inputs)\n",
        "\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 3\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return subclass_predictions\n"
      ],
      "metadata": {
        "id": "LpswB6wRmQum"
      },
      "id": "LpswB6wRmQum",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoderLossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_outputs, super_labels, sub_outputs, sub_labels, decoded, original, alpha=0.5):\n",
        "        classification_loss = nn.CrossEntropyLoss()\n",
        "        reconstruction_loss = nn.MSELoss()\n",
        "\n",
        "        loss_super = classification_loss(super_outputs, super_labels)\n",
        "        loss_sub = classification_loss(sub_outputs, sub_labels)\n",
        "        loss_recon = reconstruction_loss(decoded, original)\n",
        "\n",
        "        return alpha * (loss_super + loss_sub) + (1 - alpha) * loss_recon\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "lY_4CU5znGI_"
      },
      "id": "lY_4CU5znGI_",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCELossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_class_output, super_labels, sub_class_output, sub_labels):\n",
        "        bce_loss = nn.BCEWithLogitsLoss()\n",
        "        super_class_loss = bce_loss(super_class_output, F.one_hot(super_labels, num_classes=4).float())\n",
        "        sub_class_loss = bce_loss(sub_class_output, F.one_hot(sub_labels, num_classes=88).float())\n",
        "        return super_class_loss + sub_class_loss\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "rkXezGQIpTNB"
      },
      "id": "rkXezGQIpTNB",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "qFI4Pg1xq66R"
      },
      "id": "qFI4Pg1xq66R"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CustomEfficientNet(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        in_features = self.base_model._fc.in_features\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.extract_features(x)\n",
        "\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n"
      ],
      "metadata": {
        "id": "AYqENNBomuNV"
      },
      "id": "AYqENNBomuNV",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timm Model"
      ],
      "metadata": {
        "id": "XTelrC4V1-yt"
      },
      "id": "XTelrC4V1-yt"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "import timm"
      ],
      "metadata": {
        "id": "n_W2KGEe2djv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8ae7c3-7e2d-4f66-c0d3-b4ddbc18a093"
      },
      "id": "n_W2KGEe2djv",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEfficientNetSuper(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4):\n",
        "        super(CustomEfficientNetSuper, self).__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        in_features = self.base_model._fc.in_features\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.extract_features(x)\n",
        "\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output"
      ],
      "metadata": {
        "id": "3Fr0tHpYwiqZ"
      },
      "id": "3Fr0tHpYwiqZ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEfficientNetV2(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNetV2, self).__init__()\n",
        "        # Load a pretrained EfficientNetV2-S model\n",
        "        self.base_model = base_model\n",
        "\n",
        "        # EfficientNetV2 uses a head instead of fc for the classifier\n",
        "        in_features = self.base_model.classifier[1].in_features\n",
        "\n",
        "        # Replace the classifier with custom classifiers\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the base model\n",
        "        features = self.base_model.features(x)\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        # Classify into super and sub classes\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n"
      ],
      "metadata": {
        "id": "Xc0bSCmexpif"
      },
      "id": "Xc0bSCmexpif",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        # Load a pretrained ResNet50 model\n",
        "        base_model = base_model\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "        in_features = base_model.fc.in_features\n",
        "        base_model.fc = nn.Identity()  # Remove the original fully connected layer\n",
        "\n",
        "        self.base_model = base_model\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the base model\n",
        "        features = self.base_model(x)\n",
        "\n",
        "        # Classify into super and sub classes\n",
        "        super_class_output = self.super_class_classifier(features)\n",
        "        sub_class_output = self.sub_class_classifier(features)\n",
        "\n",
        "        return super_class_output, sub_class_output"
      ],
      "metadata": {
        "id": "CPlYDDgvOh8A"
      },
      "id": "CPlYDDgvOh8A",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetAutoencoder(nn.Module):\n",
        "    def __init__(self, num_super_classes=4, num_sub_classes=88):\n",
        "        super(MobileNetAutoencoder, self).__init__()\n",
        "        self.mobilenet_features = models.mobilenet_v2(pretrained=True).features\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.mobilenet_features,\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(1280, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 32 * 32 * 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(1280, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(1280, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        encoded = torch.flatten(encoded, 1)\n",
        "\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(-1, 3, 32, 32)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(encoded)\n",
        "        sub_class_output = self.sub_class_classifier(encoded)\n",
        "\n",
        "        return super_class_output, sub_class_output, decoded\n"
      ],
      "metadata": {
        "id": "hRad0oE0DPo5"
      },
      "id": "hRad0oE0DPo5",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(trainer, save_to_csv=False, super_name='super_pred.csv', sub_name='sub_pred.csv', autocoder=False, return_predictions=False):\n",
        "    trainer.model.eval()\n",
        "    if not trainer.test_loader:\n",
        "        raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "    superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "    subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(trainer.test_loader):\n",
        "            inputs, img_name = data[0].to(trainer.device), data[1]\n",
        "            if autocoder:\n",
        "                super_outputs, sub_outputs, _ = trainer.model(inputs)\n",
        "            else:\n",
        "                super_outputs, sub_outputs = trainer.model(inputs)\n",
        "            super_probs = F.softmax(super_outputs, dim=1)\n",
        "            sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "            _, super_predicted = torch.max(super_probs, 1)\n",
        "            _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "            superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "            superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "            superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "            subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "            subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "            subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "    if save_to_csv:\n",
        "        superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "        superclass_df.to_csv(super_name, index=False)\n",
        "\n",
        "        subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "        subclass_df.to_csv(sub_name, index=False)\n",
        "\n",
        "    if return_predictions:\n",
        "        return superclass_predictions, subclass_predictions\n"
      ],
      "metadata": {
        "id": "4Dy5mWxWkBjk"
      },
      "id": "4Dy5mWxWkBjk",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_super(trainer, save_to_csv=False, super_name='super_pred.csv', sub_name='sub_pred.csv', autocoder=False, return_predictions=False):\n",
        "    trainer.model.eval()\n",
        "    if not trainer.test_loader:\n",
        "        raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "    superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(trainer.test_loader):\n",
        "            inputs, img_name = data[0].to(trainer.device), data[1]\n",
        "            super_outputs = trainer.model(inputs)\n",
        "            super_probs = F.softmax(super_outputs, dim=1)\n",
        "            _, super_predicted = torch.max(super_probs, 1)\n",
        "\n",
        "            superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "            superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "            superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "    if save_to_csv:\n",
        "        superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "        superclass_df.to_csv(super_name, index=False)\n",
        "\n",
        "    if return_predictions:\n",
        "        return superclass_predictions\n"
      ],
      "metadata": {
        "id": "8iqvIsafwsYF"
      },
      "id": "8iqvIsafwsYF",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7941c289-d9b1-4714-b788-898b3b889f58",
      "metadata": {
        "id": "7941c289-d9b1-4714-b788-898b3b889f58"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_model(trainer, epoch):\n",
        "    for epoch in range(epoch):\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        trainer.train_epoch()\n",
        "        trainer.validate_epoch()\n",
        "        print('')\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "EgLbRQHUrGZg"
      },
      "id": "EgLbRQHUrGZg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB3 with more data"
      ],
      "metadata": {
        "id": "gJxSRn78mAYX"
      },
      "id": "gJxSRn78mAYX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "base_model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=4)\n",
        "model = base_model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_timm_super = TrainerSuper(model, criterion, optimizer, train_loader, val_loader, test_loader)\n"
      ],
      "metadata": {
        "id": "ebt5vJ8f76uV"
      },
      "id": "ebt5vJ8f76uV",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_timm_super, epoch=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Yo8hWDa7_yw",
        "outputId": "b52434a2-8b6b-466a-a799-deb940dfbe0b"
      },
      "id": "9Yo8hWDa7_yw",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.684\n",
            "Validation Loss: 0.419\n",
            "Validation Superclass Accuracy: 85.39 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.376\n",
            "Validation Loss: 0.357\n",
            "Validation Superclass Accuracy: 87.15 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.303\n",
            "Validation Loss: 0.317\n",
            "Validation Superclass Accuracy: 88.19 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.281\n",
            "Validation Loss: 0.374\n",
            "Validation Superclass Accuracy: 86.69 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.227\n",
            "Validation Loss: 0.361\n",
            "Validation Superclass Accuracy: 87.87 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.205\n",
            "Validation Loss: 0.369\n",
            "Validation Superclass Accuracy: 87.54 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.198\n",
            "Validation Loss: 0.324\n",
            "Validation Superclass Accuracy: 90.08 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.168\n",
            "Validation Loss: 0.377\n",
            "Validation Superclass Accuracy: 88.39 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.165\n",
            "Validation Loss: 0.354\n",
            "Validation Superclass Accuracy: 88.45 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.154\n",
            "Validation Loss: 0.350\n",
            "Validation Superclass Accuracy: 89.11 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.137\n",
            "Validation Loss: 0.365\n",
            "Validation Superclass Accuracy: 88.85 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.131\n",
            "Validation Loss: 0.403\n",
            "Validation Superclass Accuracy: 87.80 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.121\n",
            "Validation Loss: 0.360\n",
            "Validation Superclass Accuracy: 89.37 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.131\n",
            "Validation Loss: 0.348\n",
            "Validation Superclass Accuracy: 88.32 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.115\n",
            "Validation Loss: 0.349\n",
            "Validation Superclass Accuracy: 88.71 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB4 Super with more data"
      ],
      "metadata": {
        "id": "3cuLdu0tl9Bb"
      },
      "id": "3cuLdu0tl9Bb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "base_model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=4)\n",
        "model = base_model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_timm_efb4 = TrainerSuper(model, criterion, optimizer, train_loader, val_loader, test_loader)\n"
      ],
      "metadata": {
        "id": "3e9LAYOf7SnP"
      },
      "id": "3e9LAYOf7SnP",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_timm_efb4, 15)"
      ],
      "metadata": {
        "id": "Fqh6467k7WJN"
      },
      "id": "Fqh6467k7WJN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "base_model = timm.create_model('vgg16.tv_in1k', pretrained=True, num_classes=4)\n",
        "model = base_model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_timm_vgg16 = TrainerSuper(model, criterion, optimizer, train_loader, val_loader, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bdc56061ec7141bcb80364c39b13a596",
            "fc69be4777634b0b956e0f6971730fc0",
            "2dfb3eb8ebd04f149bba0239d2ed2be6",
            "4c34c4d0890648c989c84bd201ca26e7",
            "15271b7974014681aa0c32c0bb370877",
            "c0b3417e29ca4e21be2fa50ff3464283",
            "9f5939412e284c54be25e28ea157c0d0",
            "ca6ac4815f1a45ffab776c698d5e198b",
            "2ea68ad396ab4fcc9c3089b29381402b",
            "764e5d4d4f504e109727adae8037f1aa",
            "f4921b4ca99445e2bf5063946d525797"
          ]
        },
        "id": "9arUKEGCxPXx",
        "outputId": "71c4be0b-e6ec-4585-af11-6d9134dd271f"
      },
      "id": "9arUKEGCxPXx",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdc56061ec7141bcb80364c39b13a596"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aoc-_0cHxPa7"
      },
      "id": "Aoc-_0cHxPa7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB4 Sub"
      ],
      "metadata": {
        "id": "8oNifwxmmDyV"
      },
      "id": "8oNifwxmmDyV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "base_model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88)\n",
        "model = base_model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_timm_efb4_sub = TrainerSub(model, criterion, optimizer, train_loader, val_loader, test_loader)\n"
      ],
      "metadata": {
        "id": "32ss5KJHl8Jw"
      },
      "id": "32ss5KJHl8Jw",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_timm_efb4_sub, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRFTMipXoIOq",
        "outputId": "8f96aa39-827d-423c-ed49-9327ba47fae4"
      },
      "id": "eRFTMipXoIOq",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 2.076\n",
            "Validation Loss: 0.856\n",
            "Validation Subclass Accuracy: 72.51 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.660\n",
            "Validation Loss: 0.850\n",
            "Validation Subclass Accuracy: 79.23 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.377\n",
            "Validation Loss: 0.607\n",
            "Validation Subclass Accuracy: 82.71 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.255\n",
            "Validation Loss: 0.619\n",
            "Validation Subclass Accuracy: 81.03 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.249\n",
            "Validation Loss: 0.566\n",
            "Validation Subclass Accuracy: 82.95 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.221\n",
            "Validation Loss: 0.589\n",
            "Validation Subclass Accuracy: 82.71 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.170\n",
            "Validation Loss: 0.514\n",
            "Validation Subclass Accuracy: 85.59 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.128\n",
            "Validation Loss: 0.571\n",
            "Validation Subclass Accuracy: 84.75 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.149\n",
            "Validation Loss: 0.810\n",
            "Validation Subclass Accuracy: 84.99 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.105\n",
            "Validation Loss: 0.589\n",
            "Validation Subclass Accuracy: 85.95 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.156\n",
            "Validation Loss: 0.634\n",
            "Validation Subclass Accuracy: 84.87 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.102\n",
            "Validation Loss: 0.644\n",
            "Validation Subclass Accuracy: 86.07 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.133\n",
            "Validation Loss: 0.718\n",
            "Validation Subclass Accuracy: 84.39 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.123\n",
            "Validation Loss: 0.591\n",
            "Validation Subclass Accuracy: 86.67 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.091\n",
            "Validation Loss: 0.617\n",
            "Validation Subclass Accuracy: 85.47 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_model = trainer_timm_efb4_sub.model\n",
        "tmp_model.load_state_dict(trainer_timm_efb4_sub.best_model_wts)\n",
        "trainer_timm_efb4_sub.model = tmp_model"
      ],
      "metadata": {
        "id": "IV8h7EITQwWI"
      },
      "id": "IV8h7EITQwWI",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5KogrLDwVxu"
      },
      "id": "v5KogrLDwVxu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_super(trainer_timm_efb4_sub, save_to_csv=True, super_name='sub_preds_timm_efb4.csv', autocoder=False, return_predictions=False)"
      ],
      "metadata": {
        "id": "eJy-mYmh_z0G"
      },
      "id": "eJy-mYmh_z0G",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Replace 'super_preds_timm_efb3.csv' with the path to your file if it's in a folder\n",
        "files.download('sub_preds_timm_efb4.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YLe0NLGGOzYK",
        "outputId": "58fc885a-35d8-42e9-d6b3-98c224e5d1a8"
      },
      "id": "YLe0NLGGOzYK",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9fa2ac47-638b-4fa8-b538-7b34e919d578\", \"sub_preds_timm_efb4.csv\", 16713718)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "model = CustomEfficientNetSuper(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb5_super = TrainerSuper(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "pts2RfVb5gvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7aea3c3-42ec-4508-db79-a859da062bd7"
      },
      "id": "pts2RfVb5gvr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CD7a9rbEFBlk"
      },
      "id": "CD7a9rbEFBlk",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb5_super, epoch=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFkhg65kxBwY",
        "outputId": "f2c911cd-8f47-42bc-b1f9-197dce13a020"
      },
      "id": "gFkhg65kxBwY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 1.000\n",
            "Validation Loss: 0.820\n",
            "Validation Superclass Accuracy: 69.34 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.758\n",
            "Validation Loss: 0.903\n",
            "Validation Superclass Accuracy: 72.47 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.666\n",
            "Validation Loss: 0.638\n",
            "Validation Superclass Accuracy: 77.43 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.603\n",
            "Validation Loss: 0.599\n",
            "Validation Superclass Accuracy: 78.73 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.554\n",
            "Validation Loss: 0.627\n",
            "Validation Superclass Accuracy: 75.80 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.536\n",
            "Validation Loss: 0.548\n",
            "Validation Superclass Accuracy: 80.17 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.504\n",
            "Validation Loss: 0.535\n",
            "Validation Superclass Accuracy: 79.58 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.493\n",
            "Validation Loss: 0.533\n",
            "Validation Superclass Accuracy: 79.71 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.461\n",
            "Validation Loss: 0.538\n",
            "Validation Superclass Accuracy: 80.10 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.449\n",
            "Validation Loss: 0.501\n",
            "Validation Superclass Accuracy: 82.13 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.429\n",
            "Validation Loss: 0.508\n",
            "Validation Superclass Accuracy: 80.82 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.420\n",
            "Validation Loss: 0.468\n",
            "Validation Superclass Accuracy: 83.24 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.409\n",
            "Validation Loss: 0.471\n",
            "Validation Superclass Accuracy: 83.30 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.403\n",
            "Validation Loss: 0.490\n",
            "Validation Superclass Accuracy: 81.54 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.383\n",
            "Validation Loss: 0.477\n",
            "Validation Superclass Accuracy: 81.54 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.373\n",
            "Validation Loss: 0.503\n",
            "Validation Superclass Accuracy: 83.24 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.362\n",
            "Validation Loss: 0.500\n",
            "Validation Superclass Accuracy: 82.00 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.351\n",
            "Validation Loss: 0.517\n",
            "Validation Superclass Accuracy: 82.45 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.335\n",
            "Validation Loss: 0.536\n",
            "Validation Superclass Accuracy: 80.82 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.344\n",
            "Validation Loss: 0.492\n",
            "Validation Superclass Accuracy: 82.13 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet_V2"
      ],
      "metadata": {
        "id": "6DhDvLx_lqfE"
      },
      "id": "6DhDvLx_lqfE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "model = MobileNetAutoencoder().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_mbv2 = AutoEncoderLossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyOyMdLvloDQ",
        "outputId": "b73195ba-c36b-42d4-9ec9-03472e3efdd2"
      },
      "id": "nyOyMdLvloDQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_mbv2, epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GC1isei-XqH",
        "outputId": "2b893c7b-6244-402d-f0a4-3c86f566973c"
      },
      "id": "8GC1isei-XqH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 2.500\n",
            "Validation Loss: 2.108\n",
            "Validation Superclass Accuracy: 81.15 %\n",
            "Validation Subclass Accuracy: 31.56 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 1.990\n",
            "Validation Loss: 1.853\n",
            "Validation Superclass Accuracy: 84.84 %\n",
            "Validation Subclass Accuracy: 40.57 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 1.839\n",
            "Validation Loss: 1.698\n",
            "Validation Superclass Accuracy: 84.02 %\n",
            "Validation Subclass Accuracy: 46.31 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 1.721\n",
            "Validation Loss: 1.582\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 1.636\n",
            "Validation Loss: 1.648\n",
            "Validation Superclass Accuracy: 85.11 %\n",
            "Validation Subclass Accuracy: 50.68 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 1.600\n",
            "Validation Loss: 1.586\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 1.524\n",
            "Validation Loss: 1.600\n",
            "Validation Superclass Accuracy: 88.39 %\n",
            "Validation Subclass Accuracy: 53.01 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 1.508\n",
            "Validation Loss: 1.528\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 53.96 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 1.446\n",
            "Validation Loss: 1.429\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 55.46 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 1.414\n",
            "Validation Loss: 1.500\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 53.83 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_mbv2, save_to_csv=True, super_name='super_preds_mbv2.csv', sub_name='sub_preds_mbv2.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "nwGAVVr8ABZR"
      },
      "id": "nwGAVVr8ABZR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetB7"
      ],
      "metadata": {
        "id": "lEi6lKBrmALB"
      },
      "id": "lEi6lKBrmALB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb7 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38gC7iT-loG_",
        "outputId": "07050e69-0bcd-468e-934b-cf6d6c15103e"
      },
      "id": "38gC7iT-loG_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb7, epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws-MwB5DloKa",
        "outputId": "9224b03b-f3fe-4ad7-d4cb-28b50a7207d1"
      },
      "id": "ws-MwB5DloKa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.524\n",
            "Validation Loss: 0.774\n",
            "Validation Superclass Accuracy: 58.74 %\n",
            "Validation Subclass Accuracy: 9.29 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.271\n",
            "Validation Loss: 0.319\n",
            "Validation Superclass Accuracy: 82.79 %\n",
            "Validation Subclass Accuracy: 17.21 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.227\n",
            "Validation Loss: 0.219\n",
            "Validation Superclass Accuracy: 87.43 %\n",
            "Validation Subclass Accuracy: 19.13 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.202\n",
            "Validation Loss: 0.257\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 20.36 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.177\n",
            "Validation Loss: 0.182\n",
            "Validation Superclass Accuracy: 90.30 %\n",
            "Validation Subclass Accuracy: 24.18 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.169\n",
            "Validation Loss: 0.199\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 19.81 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.164\n",
            "Validation Loss: 0.192\n",
            "Validation Superclass Accuracy: 89.21 %\n",
            "Validation Subclass Accuracy: 23.50 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.166\n",
            "Validation Loss: 0.327\n",
            "Validation Superclass Accuracy: 80.74 %\n",
            "Validation Subclass Accuracy: 20.63 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.160\n",
            "Validation Loss: 0.276\n",
            "Validation Superclass Accuracy: 87.02 %\n",
            "Validation Subclass Accuracy: 21.58 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.168\n",
            "Validation Loss: 0.530\n",
            "Validation Superclass Accuracy: 84.56 %\n",
            "Validation Subclass Accuracy: 25.55 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB5"
      ],
      "metadata": {
        "id": "RbGGNsX7Dd2f"
      },
      "id": "RbGGNsX7Dd2f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb5 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "jLur74eUDg5S"
      },
      "id": "jLur74eUDg5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb5, epoch=10)"
      ],
      "metadata": {
        "id": "OnFIPb4IDhAF"
      },
      "id": "OnFIPb4IDhAF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetV2"
      ],
      "metadata": {
        "id": "3hhbCUp8yXx_"
      },
      "id": "3hhbCUp8yXx_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.efficientnet_v2_s(pretrained=True)\n",
        "model = CustomEfficientNetV2(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efv2 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "_zhOIvBvyaPB",
        "outputId": "aa5aa15a-d878-43db-b7dd-13d767209e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_zhOIvBvyaPB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:01<00:00, 63.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efv2, epoch=20)"
      ],
      "metadata": {
        "id": "OowQxSE1zUz-",
        "outputId": "e39604e5-58e1-4b30-99a5-6f2f9353035a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OowQxSE1zUz-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.537\n",
            "Validation Loss: 0.285\n",
            "Validation Superclass Accuracy: 81.28 %\n",
            "Validation Subclass Accuracy: 18.99 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.275\n",
            "Validation Loss: 0.238\n",
            "Validation Superclass Accuracy: 84.15 %\n",
            "Validation Subclass Accuracy: 24.18 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.228\n",
            "Validation Loss: 0.198\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 26.91 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.206\n",
            "Validation Loss: 0.169\n",
            "Validation Superclass Accuracy: 90.03 %\n",
            "Validation Subclass Accuracy: 31.01 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.181\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 89.34 %\n",
            "Validation Subclass Accuracy: 37.30 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.164\n",
            "Validation Loss: 0.169\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 38.25 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.192\n",
            "Validation Superclass Accuracy: 88.52 %\n",
            "Validation Subclass Accuracy: 38.66 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.157\n",
            "Validation Loss: 0.171\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 42.62 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.139\n",
            "Validation Loss: 0.137\n",
            "Validation Superclass Accuracy: 92.21 %\n",
            "Validation Subclass Accuracy: 43.72 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.132\n",
            "Validation Loss: 0.153\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 45.22 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.131\n",
            "Validation Loss: 0.158\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 44.81 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.124\n",
            "Validation Loss: 0.139\n",
            "Validation Superclass Accuracy: 93.03 %\n",
            "Validation Subclass Accuracy: 48.09 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.126\n",
            "Validation Loss: 0.150\n",
            "Validation Superclass Accuracy: 92.62 %\n",
            "Validation Subclass Accuracy: 47.27 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.118\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 46.31 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.112\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 49.73 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.108\n",
            "Validation Loss: 0.175\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 47.95 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.115\n",
            "Validation Loss: 0.154\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 51.37 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.103\n",
            "Validation Loss: 0.145\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 50.68 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.109\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.091\n",
            "Validation Loss: 0.126\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 52.19 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetV2 CrossEntropyLoss"
      ],
      "metadata": {
        "id": "F6z9yo0O6Oif"
      },
      "id": "F6z9yo0O6Oif"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.efficientnet_v2_s(pretrained=True)\n",
        "model = CustomEfficientNetV2(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efv2_celoss = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "J2VDBjB26THB",
        "outputId": "ca1ef56c-e112-4bb5-8224-84d338229aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J2VDBjB26THB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efv2_celoss, epoch=30)"
      ],
      "metadata": {
        "id": "yS9ReWAr6VjO",
        "outputId": "3d8d1b9c-6d3c-4083-9b5a-d27189e2e6a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yS9ReWAr6VjO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 4.430\n",
            "Validation Loss: 4.317\n",
            "Validation Superclass Accuracy: 77.46 %\n",
            "Validation Subclass Accuracy: 25.00 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 2.974\n",
            "Validation Loss: 2.708\n",
            "Validation Superclass Accuracy: 82.24 %\n",
            "Validation Subclass Accuracy: 37.70 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 2.414\n",
            "Validation Loss: 2.162\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 50.55 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 1.970\n",
            "Validation Loss: 1.823\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 56.42 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 1.756\n",
            "Validation Loss: 1.937\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 56.42 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 1.531\n",
            "Validation Loss: 1.706\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 58.74 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 1.575\n",
            "Validation Loss: 3.264\n",
            "Validation Superclass Accuracy: 76.91 %\n",
            "Validation Subclass Accuracy: 35.79 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 2.045\n",
            "Validation Loss: 2.156\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 50.96 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 1.721\n",
            "Validation Loss: 1.726\n",
            "Validation Superclass Accuracy: 90.03 %\n",
            "Validation Subclass Accuracy: 58.88 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 1.460\n",
            "Validation Loss: 1.553\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 62.70 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 1.335\n",
            "Validation Loss: 1.562\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 60.38 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 1.211\n",
            "Validation Loss: 1.541\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 64.07 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 1.138\n",
            "Validation Loss: 1.446\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 63.66 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 1.584\n",
            "Validation Loss: 2.471\n",
            "Validation Superclass Accuracy: 84.97 %\n",
            "Validation Subclass Accuracy: 55.87 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 1.547\n",
            "Validation Loss: 1.667\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 59.84 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 1.472\n",
            "Validation Loss: 3.044\n",
            "Validation Superclass Accuracy: 78.69 %\n",
            "Validation Subclass Accuracy: 40.16 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 1.766\n",
            "Validation Loss: 1.735\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 58.33 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 1.389\n",
            "Validation Loss: 1.837\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 63.11 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 1.193\n",
            "Validation Loss: 1.938\n",
            "Validation Superclass Accuracy: 88.52 %\n",
            "Validation Subclass Accuracy: 58.06 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 1.109\n",
            "Validation Loss: 1.571\n",
            "Validation Superclass Accuracy: 92.49 %\n",
            "Validation Subclass Accuracy: 64.75 %\n",
            "\n",
            "Epoch 21\n",
            "Training loss: 1.049\n",
            "Validation Loss: 1.860\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 58.74 %\n",
            "\n",
            "Epoch 22\n",
            "Training loss: 1.049\n",
            "Validation Loss: 1.658\n",
            "Validation Superclass Accuracy: 90.30 %\n",
            "Validation Subclass Accuracy: 63.93 %\n",
            "\n",
            "Epoch 23\n",
            "Training loss: 0.957\n",
            "Validation Loss: 1.628\n",
            "Validation Superclass Accuracy: 91.39 %\n",
            "Validation Subclass Accuracy: 62.84 %\n",
            "\n",
            "Epoch 24\n",
            "Training loss: 0.895\n",
            "Validation Loss: 1.513\n",
            "Validation Superclass Accuracy: 92.76 %\n",
            "Validation Subclass Accuracy: 66.67 %\n",
            "\n",
            "Epoch 25\n",
            "Training loss: 0.812\n",
            "Validation Loss: 1.557\n",
            "Validation Superclass Accuracy: 91.26 %\n",
            "Validation Subclass Accuracy: 68.03 %\n",
            "\n",
            "Epoch 26\n",
            "Training loss: 0.839\n",
            "Validation Loss: 1.703\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 64.62 %\n",
            "\n",
            "Epoch 27\n",
            "Training loss: 0.862\n",
            "Validation Loss: 1.546\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 64.48 %\n",
            "\n",
            "Epoch 28\n",
            "Training loss: 0.960\n",
            "Validation Loss: 1.620\n",
            "Validation Superclass Accuracy: 91.12 %\n",
            "Validation Subclass Accuracy: 62.84 %\n",
            "\n",
            "Epoch 29\n",
            "Training loss: 0.899\n",
            "Validation Loss: 1.499\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 64.62 %\n",
            "\n",
            "Epoch 30\n",
            "Training loss: 0.776\n",
            "Validation Loss: 1.515\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 66.80 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50"
      ],
      "metadata": {
        "id": "5omYNluLPthV"
      },
      "id": "5omYNluLPthV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "model = CustomResNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_res50 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "Y47e_JHSPu9I"
      },
      "id": "Y47e_JHSPu9I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_res50, epoch=30)"
      ],
      "metadata": {
        "id": "1IrxzQt0PvAu",
        "outputId": "0a1cd9b5-f89d-4a29-c7a0-f90ec1e1e3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1IrxzQt0PvAu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.461\n",
            "Validation Loss: 0.331\n",
            "Validation Superclass Accuracy: 81.01 %\n",
            "Validation Subclass Accuracy: 28.69 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.240\n",
            "Validation Loss: 0.247\n",
            "Validation Superclass Accuracy: 85.52 %\n",
            "Validation Subclass Accuracy: 33.33 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.212\n",
            "Validation Loss: 0.214\n",
            "Validation Superclass Accuracy: 86.75 %\n",
            "Validation Subclass Accuracy: 39.48 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.195\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.66 %\n",
            "Validation Subclass Accuracy: 38.93 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.175\n",
            "Validation Loss: 0.180\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 43.31 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.167\n",
            "Validation Loss: 0.154\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 43.85 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.156\n",
            "Validation Loss: 0.193\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 45.63 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.156\n",
            "Validation Loss: 0.191\n",
            "Validation Superclass Accuracy: 88.25 %\n",
            "Validation Subclass Accuracy: 43.31 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.149\n",
            "Validation Loss: 0.207\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 44.26 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.150\n",
            "Validation Loss: 0.222\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 46.72 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.137\n",
            "Validation Loss: 0.177\n",
            "Validation Superclass Accuracy: 89.07 %\n",
            "Validation Subclass Accuracy: 44.13 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.139\n",
            "Validation Loss: 0.161\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 48.91 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.128\n",
            "Validation Loss: 0.188\n",
            "Validation Superclass Accuracy: 89.21 %\n",
            "Validation Subclass Accuracy: 49.45 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.128\n",
            "Validation Loss: 0.185\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 49.73 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.121\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.118\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 49.45 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.110\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 91.12 %\n",
            "Validation Subclass Accuracy: 50.00 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.115\n",
            "Validation Loss: 0.161\n",
            "Validation Superclass Accuracy: 89.75 %\n",
            "Validation Subclass Accuracy: 46.86 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.116\n",
            "Validation Loss: 0.135\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 53.55 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.112\n",
            "Validation Loss: 0.260\n",
            "Validation Superclass Accuracy: 89.07 %\n",
            "Validation Subclass Accuracy: 48.63 %\n",
            "\n",
            "Epoch 21\n",
            "Training loss: 0.107\n",
            "Validation Loss: 0.162\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 49.59 %\n",
            "\n",
            "Epoch 22\n",
            "Training loss: 0.106\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 23\n",
            "Training loss: 0.110\n",
            "Validation Loss: 0.145\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 50.27 %\n",
            "\n",
            "Epoch 24\n",
            "Training loss: 0.101\n",
            "Validation Loss: 0.156\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 47.68 %\n",
            "\n",
            "Epoch 25\n",
            "Training loss: 0.104\n",
            "Validation Loss: 0.140\n",
            "Validation Superclass Accuracy: 92.76 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 26\n",
            "Training loss: 0.096\n",
            "Validation Loss: 0.151\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 53.96 %\n",
            "\n",
            "Epoch 27\n",
            "Training loss: 0.100\n",
            "Validation Loss: 0.220\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 45.77 %\n",
            "\n",
            "Epoch 28\n",
            "Training loss: 0.099\n",
            "Validation Loss: 0.149\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 53.01 %\n",
            "\n",
            "Epoch 29\n",
            "Training loss: 0.094\n",
            "Validation Loss: 0.160\n",
            "Validation Superclass Accuracy: 90.44 %\n",
            "Validation Subclass Accuracy: 52.87 %\n",
            "\n",
            "Epoch 30\n",
            "Training loss: 0.092\n",
            "Validation Loss: 0.133\n",
            "Validation Superclass Accuracy: 91.67 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "model = CustomResNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_res18 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "UKayAzN9b7xH",
        "outputId": "9fc7fbca-5a9d-4a32-9f3b-a9a659cc8f2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UKayAzN9b7xH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 180MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_res18, epoch=20)"
      ],
      "metadata": {
        "id": "1W37J4jacaP6",
        "outputId": "0b61bfd5-67b8-4b19-91fa-4edee85709f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1W37J4jacaP6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.387\n",
            "Validation Loss: 0.297\n",
            "Validation Superclass Accuracy: 78.28 %\n",
            "Validation Subclass Accuracy: 18.31 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.271\n",
            "Validation Loss: 0.265\n",
            "Validation Superclass Accuracy: 81.42 %\n",
            "Validation Subclass Accuracy: 20.77 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.249\n",
            "Validation Loss: 0.267\n",
            "Validation Superclass Accuracy: 82.10 %\n",
            "Validation Subclass Accuracy: 20.77 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.228\n",
            "Validation Loss: 0.240\n",
            "Validation Superclass Accuracy: 85.11 %\n",
            "Validation Subclass Accuracy: 22.54 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.216\n",
            "Validation Loss: 0.249\n",
            "Validation Superclass Accuracy: 84.43 %\n",
            "Validation Subclass Accuracy: 21.99 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.212\n",
            "Validation Loss: 0.220\n",
            "Validation Superclass Accuracy: 85.93 %\n",
            "Validation Subclass Accuracy: 23.36 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.196\n",
            "Validation Loss: 0.225\n",
            "Validation Superclass Accuracy: 85.25 %\n",
            "Validation Subclass Accuracy: 24.86 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.191\n",
            "Validation Loss: 0.193\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 25.00 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.190\n",
            "Validation Loss: 0.173\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 25.68 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.180\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 25.55 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.177\n",
            "Validation Loss: 0.174\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 29.10 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.173\n",
            "Validation Loss: 0.218\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 27.46 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.171\n",
            "Validation Loss: 0.181\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 27.32 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.155\n",
            "Validation Loss: 0.204\n",
            "Validation Superclass Accuracy: 87.02 %\n",
            "Validation Subclass Accuracy: 27.60 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.222\n",
            "Validation Superclass Accuracy: 85.66 %\n",
            "Validation Subclass Accuracy: 29.51 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.155\n",
            "Validation Loss: 0.204\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 28.42 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 89.75 %\n",
            "Validation Subclass Accuracy: 30.60 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.143\n",
            "Validation Loss: 0.195\n",
            "Validation Superclass Accuracy: 87.70 %\n",
            "Validation Subclass Accuracy: 31.97 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.146\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 33.06 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.145\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 32.65 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Test Data"
      ],
      "metadata": {
        "id": "NPR32fgxcsvO"
      },
      "id": "NPR32fgxcsvO"
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_mbv2, save_to_csv=True, super_name='super_preds_mbv2.csv', sub_name='sub_preds_mbv2.csv', autocoder=True, return_predictions=False)"
      ],
      "metadata": {
        "id": "VpfHLU2Wcz5K"
      },
      "id": "VpfHLU2Wcz5K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efb5, save_to_csv=True, super_name='super_preds_efb5.csv', sub_name='sub_preds_efb5.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "Yx0SFUe0c1kc"
      },
      "id": "Yx0SFUe0c1kc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efb7, save_to_csv=True, super_name='super_preds_efb7.csv', sub_name='sub_preds_efb7.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "qFwKAHZNc1sz"
      },
      "id": "qFwKAHZNc1sz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_res18, save_to_csv=True, super_name='super_preds_res18.csv', sub_name='sub_preds_res18.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "RjEq7Pcnc1zb"
      },
      "id": "RjEq7Pcnc1zb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_res50, save_to_csv=True, super_name='super_preds_res50.csv', sub_name='sub_preds_res50.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "rAxXYY4Rc15V"
      },
      "id": "rAxXYY4Rc15V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efv2, save_to_csv=True, super_name='super_preds_efv2.csv', sub_name='sub_preds_efv2.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "5aqMBOCG5jXE"
      },
      "id": "5aqMBOCG5jXE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efv2_celoss, save_to_csv=True, super_name='super_preds_efv2celoss.csv', sub_name='sub_preds_efv2celoss.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "kjTaux4iBY3z"
      },
      "id": "kjTaux4iBY3z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_df(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['probs'] = df['subclass_probs']\n",
        "    df['probs'] = df['probs'].str.strip('[]').str.split()\n",
        "    df['probs'] = df['probs'].apply(lambda x: [float(i) for i in x[:-1]])\n",
        "    df['Max_Prob'] = df['probs'].apply(max)\n",
        "    df['Target'] = df['probs'].apply(lambda x: x.index(max(x)))\n",
        "    df['Target'] = df['Target'].where(df['Max_Prob'] > threshold, 87)\n",
        "    # print distribution\n",
        "    print(df['Target'].value_counts())\n",
        "    return df"
      ],
      "metadata": {
        "id": "IkBsY_oU5nyO"
      },
      "id": "IkBsY_oU5nyO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_df(df, output_name):\n",
        "    output = pd.DataFrame({'ID': df['image'], 'Target': df['Target']})\n",
        "    output.to_csv(output_name, index=False)\n",
        "    return output"
      ],
      "metadata": {
        "id": "mTC8hxcD5swP"
      },
      "id": "mTC8hxcD5swP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bdc56061ec7141bcb80364c39b13a596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc69be4777634b0b956e0f6971730fc0",
              "IPY_MODEL_2dfb3eb8ebd04f149bba0239d2ed2be6",
              "IPY_MODEL_4c34c4d0890648c989c84bd201ca26e7"
            ],
            "layout": "IPY_MODEL_15271b7974014681aa0c32c0bb370877"
          }
        },
        "fc69be4777634b0b956e0f6971730fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b3417e29ca4e21be2fa50ff3464283",
            "placeholder": "​",
            "style": "IPY_MODEL_9f5939412e284c54be25e28ea157c0d0",
            "value": "model.safetensors: 100%"
          }
        },
        "2dfb3eb8ebd04f149bba0239d2ed2be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca6ac4815f1a45ffab776c698d5e198b",
            "max": 553432986,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ea68ad396ab4fcc9c3089b29381402b",
            "value": 553432986
          }
        },
        "4c34c4d0890648c989c84bd201ca26e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_764e5d4d4f504e109727adae8037f1aa",
            "placeholder": "​",
            "style": "IPY_MODEL_f4921b4ca99445e2bf5063946d525797",
            "value": " 553M/553M [00:28&lt;00:00, 19.9MB/s]"
          }
        },
        "15271b7974014681aa0c32c0bb370877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b3417e29ca4e21be2fa50ff3464283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5939412e284c54be25e28ea157c0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca6ac4815f1a45ffab776c698d5e198b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea68ad396ab4fcc9c3089b29381402b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "764e5d4d4f504e109727adae8037f1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4921b4ca99445e2bf5063946d525797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}