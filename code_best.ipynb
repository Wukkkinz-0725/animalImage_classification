{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wukkkinz-0725/animalImage_classification/blob/master/code_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Wukkkinz-0725/animalImage_classification.git"
      ],
      "metadata": {
        "id": "p0Y0iPo8SjIX",
        "outputId": "19610f96-f6ec-4fd3-ae17-7b8fb0626254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p0Y0iPo8SjIX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'animalImage_classification'...\n",
            "remote: Enumerating objects: 18619, done.\u001b[K\n",
            "remote: Counting objects: 100% (18619/18619), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 18619 (delta 18569), reused 18581 (delta 18549), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18619/18619), 13.82 MiB | 22.11 MiB/s, done.\n",
            "Resolving deltas: 100% (18569/18569), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdj9jVAxjm6v",
        "outputId": "1ec724e7-e33f-478a-f627-975d3d113507"
      },
      "id": "Cdj9jVAxjm6v",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "S_Q8363gRlIE"
      },
      "id": "S_Q8363gRlIE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./animalImage_classification/Released_Data')"
      ],
      "metadata": {
        "id": "DCG4pGJHR4QO"
      },
      "id": "DCG4pGJHR4QO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "ANiA5CLoC_E2"
      },
      "id": "ANiA5CLoC_E2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
      "metadata": {
        "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c"
      },
      "outputs": [],
      "source": [
        "# Create Dataset class for multilabel classification\n",
        "class MultiClassImageDataset(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.ann_df['image'][idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        super_idx = self.ann_df['superclass_index'][idx]\n",
        "        super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "        sub_idx = self.ann_df['subclass_index'][idx]\n",
        "        sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "class MultiClassImageTestDataset(Dataset):\n",
        "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): # Count files in img_dir\n",
        "        return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = str(idx) + '.jpg'\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_split(dataset, stratify_by='superclass_index'):\n",
        "    from torch.utils.data import Subset\n",
        "    # Extract labels for stratification\n",
        "    labels = np.array(dataset.ann_df[stratify_by])\n",
        "\n",
        "    # Perform stratified split\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1)\n",
        "    train_idx, val_idx = next(sss.split(np.zeros(len(labels)), labels))\n",
        "\n",
        "    # Create train and validation subsets\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "    return train_subset, val_subset"
      ],
      "metadata": {
        "id": "N_YUkjtNdSLj"
      },
      "id": "N_YUkjtNdSLj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_pil(tensor):\n",
        "    to_pil_image = transforms.ToPILImage()\n",
        "    pil_image = to_pil_image(tensor)\n",
        "    return pil_image"
      ],
      "metadata": {
        "id": "ztM74-BuruIO"
      },
      "id": "ztM74-BuruIO",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Load CIFAR-10 and CIFAR-100 datasets\n",
        "cifar10_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "cifar100_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Initialize counters and storage\n",
        "class_counts = {0: 0, 1: 0, 2: 0, 3: 0}  # bird, dog, reptile, novel\n",
        "filtered_images = []\n",
        "\n",
        "# Process CIFAR-10 (bird and dog)\n",
        "for image, label in cifar10_dataset:\n",
        "    if label in [2, 5]:  # CIFAR-10 labels for bird and dog\n",
        "        superclass = 0 if label == 2 else 1  # Convert to new superclass label\n",
        "        if class_counts[superclass] < 2000:\n",
        "            filtered_images.append((image, superclass, 87))  # subclass 87\n",
        "            class_counts[superclass] += 1\n",
        "\n",
        "for image, label in cifar10_dataset:\n",
        "    if label == 6:  # CIFAR-10 labels for bird and dog\n",
        "        if class_counts[2] < 1000:\n",
        "            filtered_images.append((image, 2, 87))  # subclass 87\n",
        "            class_counts[2] += 1\n",
        "\n",
        "\n",
        "# Process CIFAR-100 (reptile)\n",
        "for image, label in cifar100_dataset:\n",
        "    if 76 <= label <= 80:  # CIFAR-100 label for reptile\n",
        "        if class_counts[2] < 2000:\n",
        "            filtered_images.append((image, 2, 87))  # superclass 2, subclass 87\n",
        "            class_counts[2] += 1\n",
        "\n",
        "# Add novel images\n",
        "while class_counts[3] < 3000:\n",
        "    random_image, label = random.choice(cifar10_dataset)  # Randomly select an image\n",
        "    if label not in [2, 5, 6]:  # Exclude classes 2, 5, and 6\n",
        "        filtered_images.append((random_image, 3, 87))  # superclass 3, subclass 87\n",
        "        class_counts[3] += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBtFBx_1eZ8r",
        "outputId": "2d90b723-e78b-456b-a129-e096b2f95e85"
      },
      "id": "DBtFBx_1eZ8r",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:11<00:00, 15047989.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:11<00:00, 15197543.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_images[0]"
      ],
      "metadata": {
        "id": "IlgjYRLSvQde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98877196-473c-4ef9-d189-bffda4b715ea"
      },
      "id": "IlgjYRLSvQde",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.6431, 0.4118, 0.4627,  ..., 0.4275, 0.4235, 0.3569],\n",
              "          [0.6549, 0.4549, 0.2824,  ..., 0.4118, 0.4118, 0.3490],\n",
              "          [0.5490, 0.5569, 0.4667,  ..., 0.4078, 0.3294, 0.3059],\n",
              "          ...,\n",
              "          [0.5451, 0.5569, 0.5294,  ..., 0.3490, 0.3804, 0.4941],\n",
              "          [0.6392, 0.6000, 0.5725,  ..., 0.3333, 0.3843, 0.4980],\n",
              "          [0.7176, 0.6902, 0.6039,  ..., 0.3686, 0.3569, 0.4784]],\n",
              " \n",
              "         [[0.8078, 0.5490, 0.5804,  ..., 0.5765, 0.5765, 0.5059],\n",
              "          [0.8353, 0.6275, 0.4275,  ..., 0.5569, 0.5569, 0.4980],\n",
              "          [0.7490, 0.7569, 0.6392,  ..., 0.5451, 0.4706, 0.4510],\n",
              "          ...,\n",
              "          [0.5804, 0.6078, 0.6118,  ..., 0.5255, 0.5804, 0.6902],\n",
              "          [0.6157, 0.6431, 0.6431,  ..., 0.5098, 0.5804, 0.6980],\n",
              "          [0.6000, 0.7137, 0.6039,  ..., 0.5255, 0.5216, 0.6667]],\n",
              " \n",
              "         [[0.3294, 0.2392, 0.3961,  ..., 0.2863, 0.2706, 0.2235],\n",
              "          [0.3294, 0.1922, 0.1686,  ..., 0.3098, 0.2824, 0.2235],\n",
              "          [0.2549, 0.2588, 0.3098,  ..., 0.3294, 0.2275, 0.1922],\n",
              "          ...,\n",
              "          [0.3176, 0.2902, 0.2824,  ..., 0.1098, 0.0941, 0.1922],\n",
              "          [0.3333, 0.3216, 0.3529,  ..., 0.0745, 0.1059, 0.1882],\n",
              "          [0.4000, 0.4549, 0.3922,  ..., 0.1137, 0.1020, 0.1725]]]),\n",
              " 0,\n",
              " 87)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_filtered_image(idx):\n",
        "    image = filtered_images[idx]\n",
        "    print(image[1:])\n",
        "    tensor_to_pil(image[0])"
      ],
      "metadata": {
        "id": "JkPTt5xErL_i"
      },
      "id": "JkPTt5xErL_i",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read existing data from CSV file or create a new DataFrame if the file doesn't exist\n",
        "csv_file = 'train_data.csv'\n",
        "new_csv_file = 'train_data_v1.csv'\n",
        "existing_df = pd.read_csv(csv_file)\n",
        "DROP_IDX = [534, 589, 1013, 1231, 1274, 1501, 1827, 1922, 2191, 2195, 2197, 2548, 2575, 2578,\n",
        "2690, 3049, 3099, 3100, 3292, 3481, 3702, 3743, 4099, 4565, 4850, 4914, 5039, 5150,\n",
        "5222, 5350, 5557, 5726, 6037, 6262]\n",
        "existing_df.drop(DROP_IDX, axis=0)\n",
        "# Prepare CSV data for new images\n",
        "new_csv_data = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "for i, filtered_image in enumerate(filtered_images, start=6322):\n",
        "    file_name = f'{i}.jpg'\n",
        "    image_path = os.path.join('train_shuffle', file_name)\n",
        "    image = transforms.ToPILImage()(filtered_image[0])\n",
        "    image.save(image_path)\n",
        "    # Update CSV data\n",
        "    new_csv_data['image'].append(file_name)\n",
        "    new_csv_data['superclass_index'].append(filtered_image[1])\n",
        "    new_csv_data['subclass_index'].append(filtered_image[2])\n",
        "\n",
        "new_df = pd.DataFrame(new_csv_data)\n",
        "combined_df = existing_df.append(new_df, ignore_index=True)\n",
        "\n",
        "# Write the combined DataFrame to the CSV file\n",
        "combined_df.to_csv(new_csv_file, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErMMb3UYexxJ",
        "outputId": "ad4c5f6a-2cf3-47a9-894d-d1e279713689"
      },
      "id": "ErMMb3UYexxJ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-3c0448cc6feb>:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  combined_df = existing_df.append(new_df, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "MybZXEir47S2"
      },
      "id": "MybZXEir47S2"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e7398553-8842-4ad8-b348-767921a22482",
      "metadata": {
        "id": "e7398553-8842-4ad8-b348-767921a22482"
      },
      "outputs": [],
      "source": [
        "train_ann_df = pd.read_csv('train_data_v1.csv')\n",
        "super_map_df = pd.read_csv('superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
        "\n",
        "train_img_dir = 'train_shuffle'\n",
        "test_img_dir = 'test_shuffle'\n",
        "\n",
        "image_preprocessing = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
        "    transforms.RandomVerticalFlip(),    # vertical flip of the image\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),  # random color jitter\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # random translation\n",
        "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),  # random crop and resize\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # normalization\n",
        "])\n",
        "\n",
        "# Create train and val split\n",
        "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
        "train_dataset, val_dataset = stratified_split(train_dataset)\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=4)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True,\n",
        "                        num_workers=4)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=1,\n",
        "                         shuffle=False,\n",
        "                         num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure it's read in RGB format\n",
        "    return image"
      ],
      "metadata": {
        "id": "PQEB38eRlGaY"
      },
      "id": "PQEB38eRlGaY",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainers"
      ],
      "metadata": {
        "id": "QQYpXee3q_gZ"
      },
      "id": "QQYpXee3q_gZ"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840",
      "metadata": {
        "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            loss += self.criterion(super_outputs, super_labels)\n",
        "            loss += self.criterion(sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                loss += self.criterion(super_outputs, super_labels)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                loss += self.criterion(sub_outputs, sub_labels)\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerSuper():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "        self.best_model_wts = None\n",
        "        self.best_loss = 0\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            loss += self.criterion(super_outputs, super_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        import copy\n",
        "        super_correct, total = 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                loss += self.criterion(super_outputs, super_labels)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "        if 100 * super_correct / total > self.best_accuracy:\n",
        "            self.best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            self.best_accuracy = 100 * super_correct / total\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions\n"
      ],
      "metadata": {
        "id": "0QAnsPv8o1N_"
      },
      "id": "0QAnsPv8o1N_",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoderLossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_outputs, super_labels, sub_outputs, sub_labels, decoded, original, alpha=0.5):\n",
        "        classification_loss = nn.CrossEntropyLoss()\n",
        "        reconstruction_loss = nn.MSELoss()\n",
        "\n",
        "        loss_super = classification_loss(super_outputs, super_labels)\n",
        "        loss_sub = classification_loss(sub_outputs, sub_labels)\n",
        "        loss_recon = reconstruction_loss(decoded, original)\n",
        "\n",
        "        return alpha * (loss_super + loss_sub) + (1 - alpha) * loss_recon\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "lY_4CU5znGI_"
      },
      "id": "lY_4CU5znGI_",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCELossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_class_output, super_labels, sub_class_output, sub_labels):\n",
        "        bce_loss = nn.BCEWithLogitsLoss()\n",
        "        super_class_loss = bce_loss(super_class_output, F.one_hot(super_labels, num_classes=4).float())\n",
        "        sub_class_loss = bce_loss(sub_class_output, F.one_hot(sub_labels, num_classes=88).float())\n",
        "        return super_class_loss + sub_class_loss\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "rkXezGQIpTNB"
      },
      "id": "rkXezGQIpTNB",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "qFI4Pg1xq66R"
      },
      "id": "qFI4Pg1xq66R"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CustomEfficientNet(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        in_features = self.base_model._fc.in_features\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.extract_features(x)\n",
        "\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n"
      ],
      "metadata": {
        "id": "AYqENNBomuNV"
      },
      "id": "AYqENNBomuNV",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timm Model"
      ],
      "metadata": {
        "id": "XTelrC4V1-yt"
      },
      "id": "XTelrC4V1-yt"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "import timm"
      ],
      "metadata": {
        "id": "n_W2KGEe2djv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02f7dc2-5d4d-4058-91de-96db91502790"
      },
      "id": "n_W2KGEe2djv",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEfficientNetSuper(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4):\n",
        "        super(CustomEfficientNetSuper, self).__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        in_features = self.base_model._fc.in_features\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.extract_features(x)\n",
        "\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output"
      ],
      "metadata": {
        "id": "3Fr0tHpYwiqZ"
      },
      "id": "3Fr0tHpYwiqZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEfficientNetV2(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNetV2, self).__init__()\n",
        "        # Load a pretrained EfficientNetV2-S model\n",
        "        self.base_model = base_model\n",
        "\n",
        "        # EfficientNetV2 uses a head instead of fc for the classifier\n",
        "        in_features = self.base_model.classifier[1].in_features\n",
        "\n",
        "        # Replace the classifier with custom classifiers\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the base model\n",
        "        features = self.base_model.features(x)\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        # Classify into super and sub classes\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n"
      ],
      "metadata": {
        "id": "Xc0bSCmexpif"
      },
      "id": "Xc0bSCmexpif",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        # Load a pretrained ResNet50 model\n",
        "        base_model = base_model\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "        in_features = base_model.fc.in_features\n",
        "        base_model.fc = nn.Identity()  # Remove the original fully connected layer\n",
        "\n",
        "        self.base_model = base_model\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the base model\n",
        "        features = self.base_model(x)\n",
        "\n",
        "        # Classify into super and sub classes\n",
        "        super_class_output = self.super_class_classifier(features)\n",
        "        sub_class_output = self.sub_class_classifier(features)\n",
        "\n",
        "        return super_class_output, sub_class_output"
      ],
      "metadata": {
        "id": "CPlYDDgvOh8A"
      },
      "id": "CPlYDDgvOh8A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetAutoencoder(nn.Module):\n",
        "    def __init__(self, num_super_classes=4, num_sub_classes=88):\n",
        "        super(MobileNetAutoencoder, self).__init__()\n",
        "        self.mobilenet_features = models.mobilenet_v2(pretrained=True).features\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.mobilenet_features,\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(1280, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 32 * 32 * 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(1280, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(1280, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        encoded = torch.flatten(encoded, 1)\n",
        "\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(-1, 3, 32, 32)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(encoded)\n",
        "        sub_class_output = self.sub_class_classifier(encoded)\n",
        "\n",
        "        return super_class_output, sub_class_output, decoded\n"
      ],
      "metadata": {
        "id": "hRad0oE0DPo5"
      },
      "id": "hRad0oE0DPo5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(trainer, save_to_csv=False, super_name='super_pred.csv', sub_name='sub_pred.csv', autocoder=False, return_predictions=False):\n",
        "    trainer.model.eval()\n",
        "    if not trainer.test_loader:\n",
        "        raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "    superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "    subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(trainer.test_loader):\n",
        "            inputs, img_name = data[0].to(trainer.device), data[1]\n",
        "            if autocoder:\n",
        "                super_outputs, sub_outputs, _ = trainer.model(inputs)\n",
        "            else:\n",
        "                super_outputs, sub_outputs = trainer.model(inputs)\n",
        "            super_probs = F.softmax(super_outputs, dim=1)\n",
        "            sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "            _, super_predicted = torch.max(super_probs, 1)\n",
        "            _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "            superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "            superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "            superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "            subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "            subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "            subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "    if save_to_csv:\n",
        "        superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "        superclass_df.to_csv(super_name, index=False)\n",
        "\n",
        "        subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "        subclass_df.to_csv(sub_name, index=False)\n",
        "\n",
        "    if return_predictions:\n",
        "        return superclass_predictions, subclass_predictions\n"
      ],
      "metadata": {
        "id": "4Dy5mWxWkBjk"
      },
      "id": "4Dy5mWxWkBjk",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_super(trainer, save_to_csv=False, super_name='super_pred.csv', sub_name='sub_pred.csv', autocoder=False, return_predictions=False):\n",
        "    trainer.model.eval()\n",
        "    if not trainer.test_loader:\n",
        "        raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "    superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(trainer.test_loader):\n",
        "            inputs, img_name = data[0].to(trainer.device), data[1]\n",
        "            super_outputs = trainer.model(inputs)\n",
        "            super_probs = F.softmax(super_outputs, dim=1)\n",
        "            _, super_predicted = torch.max(super_probs, 1)\n",
        "\n",
        "            superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "            superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "            superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "    if save_to_csv:\n",
        "        superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "        superclass_df.to_csv(super_name, index=False)\n",
        "\n",
        "    if return_predictions:\n",
        "        return superclass_predictions\n"
      ],
      "metadata": {
        "id": "8iqvIsafwsYF"
      },
      "id": "8iqvIsafwsYF",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7941c289-d9b1-4714-b788-898b3b889f58",
      "metadata": {
        "id": "7941c289-d9b1-4714-b788-898b3b889f58"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_model(trainer, epoch):\n",
        "    for epoch in range(epoch):\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        trainer.train_epoch()\n",
        "        trainer.validate_epoch()\n",
        "        print('')\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "EgLbRQHUrGZg"
      },
      "id": "EgLbRQHUrGZg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "base_model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=4)\n",
        "model = base_model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_timm_super = TrainerSuper(model, criterion, optimizer, train_loader, val_loader, test_loader)\n"
      ],
      "metadata": {
        "id": "ebt5vJ8f76uV"
      },
      "id": "ebt5vJ8f76uV",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_timm_super, epoch=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "9Yo8hWDa7_yw",
        "outputId": "e517863e-34bb-4b99-9c7f-13c6541c4823"
      },
      "id": "9Yo8hWDa7_yw",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ba2557f7d88a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_timm_super\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-f1a86651b1f6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainer, epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-ecad3ad23931>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 15.77 GiB of which 4.38 MiB is free. Process 4575 has 15.77 GiB memory in use. Of the allocated memory 15.06 GiB is allocated by PyTorch, and 319.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_super(trainer_timm_super, save_to_csv=True, super_name='super_pred_timm_efb2.csv', autocoder=False, return_predictions=False)"
      ],
      "metadata": {
        "id": "eJy-mYmh_z0G"
      },
      "id": "eJy-mYmh_z0G",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "model = CustomEfficientNetSuper(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb5_super = TrainerSuper(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "pts2RfVb5gvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7aea3c3-42ec-4508-db79-a859da062bd7"
      },
      "id": "pts2RfVb5gvr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb5_super, epoch=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFkhg65kxBwY",
        "outputId": "f2c911cd-8f47-42bc-b1f9-197dce13a020"
      },
      "id": "gFkhg65kxBwY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 1.000\n",
            "Validation Loss: 0.820\n",
            "Validation Superclass Accuracy: 69.34 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.758\n",
            "Validation Loss: 0.903\n",
            "Validation Superclass Accuracy: 72.47 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.666\n",
            "Validation Loss: 0.638\n",
            "Validation Superclass Accuracy: 77.43 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.603\n",
            "Validation Loss: 0.599\n",
            "Validation Superclass Accuracy: 78.73 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.554\n",
            "Validation Loss: 0.627\n",
            "Validation Superclass Accuracy: 75.80 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.536\n",
            "Validation Loss: 0.548\n",
            "Validation Superclass Accuracy: 80.17 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.504\n",
            "Validation Loss: 0.535\n",
            "Validation Superclass Accuracy: 79.58 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.493\n",
            "Validation Loss: 0.533\n",
            "Validation Superclass Accuracy: 79.71 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.461\n",
            "Validation Loss: 0.538\n",
            "Validation Superclass Accuracy: 80.10 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.449\n",
            "Validation Loss: 0.501\n",
            "Validation Superclass Accuracy: 82.13 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.429\n",
            "Validation Loss: 0.508\n",
            "Validation Superclass Accuracy: 80.82 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.420\n",
            "Validation Loss: 0.468\n",
            "Validation Superclass Accuracy: 83.24 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.409\n",
            "Validation Loss: 0.471\n",
            "Validation Superclass Accuracy: 83.30 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.403\n",
            "Validation Loss: 0.490\n",
            "Validation Superclass Accuracy: 81.54 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.383\n",
            "Validation Loss: 0.477\n",
            "Validation Superclass Accuracy: 81.54 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.373\n",
            "Validation Loss: 0.503\n",
            "Validation Superclass Accuracy: 83.24 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.362\n",
            "Validation Loss: 0.500\n",
            "Validation Superclass Accuracy: 82.00 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.351\n",
            "Validation Loss: 0.517\n",
            "Validation Superclass Accuracy: 82.45 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.335\n",
            "Validation Loss: 0.536\n",
            "Validation Superclass Accuracy: 80.82 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.344\n",
            "Validation Loss: 0.492\n",
            "Validation Superclass Accuracy: 82.13 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet_V2"
      ],
      "metadata": {
        "id": "6DhDvLx_lqfE"
      },
      "id": "6DhDvLx_lqfE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "model = MobileNetAutoencoder().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_mbv2 = AutoEncoderLossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyOyMdLvloDQ",
        "outputId": "b73195ba-c36b-42d4-9ec9-03472e3efdd2"
      },
      "id": "nyOyMdLvloDQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_mbv2, epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GC1isei-XqH",
        "outputId": "2b893c7b-6244-402d-f0a4-3c86f566973c"
      },
      "id": "8GC1isei-XqH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 2.500\n",
            "Validation Loss: 2.108\n",
            "Validation Superclass Accuracy: 81.15 %\n",
            "Validation Subclass Accuracy: 31.56 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 1.990\n",
            "Validation Loss: 1.853\n",
            "Validation Superclass Accuracy: 84.84 %\n",
            "Validation Subclass Accuracy: 40.57 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 1.839\n",
            "Validation Loss: 1.698\n",
            "Validation Superclass Accuracy: 84.02 %\n",
            "Validation Subclass Accuracy: 46.31 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 1.721\n",
            "Validation Loss: 1.582\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 1.636\n",
            "Validation Loss: 1.648\n",
            "Validation Superclass Accuracy: 85.11 %\n",
            "Validation Subclass Accuracy: 50.68 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 1.600\n",
            "Validation Loss: 1.586\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 1.524\n",
            "Validation Loss: 1.600\n",
            "Validation Superclass Accuracy: 88.39 %\n",
            "Validation Subclass Accuracy: 53.01 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 1.508\n",
            "Validation Loss: 1.528\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 53.96 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 1.446\n",
            "Validation Loss: 1.429\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 55.46 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 1.414\n",
            "Validation Loss: 1.500\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 53.83 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_mbv2, save_to_csv=True, super_name='super_preds_mbv2.csv', sub_name='sub_preds_mbv2.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "nwGAVVr8ABZR"
      },
      "id": "nwGAVVr8ABZR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetB7"
      ],
      "metadata": {
        "id": "lEi6lKBrmALB"
      },
      "id": "lEi6lKBrmALB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb7 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38gC7iT-loG_",
        "outputId": "07050e69-0bcd-468e-934b-cf6d6c15103e"
      },
      "id": "38gC7iT-loG_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb7, epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws-MwB5DloKa",
        "outputId": "9224b03b-f3fe-4ad7-d4cb-28b50a7207d1"
      },
      "id": "ws-MwB5DloKa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.524\n",
            "Validation Loss: 0.774\n",
            "Validation Superclass Accuracy: 58.74 %\n",
            "Validation Subclass Accuracy: 9.29 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.271\n",
            "Validation Loss: 0.319\n",
            "Validation Superclass Accuracy: 82.79 %\n",
            "Validation Subclass Accuracy: 17.21 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.227\n",
            "Validation Loss: 0.219\n",
            "Validation Superclass Accuracy: 87.43 %\n",
            "Validation Subclass Accuracy: 19.13 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.202\n",
            "Validation Loss: 0.257\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 20.36 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.177\n",
            "Validation Loss: 0.182\n",
            "Validation Superclass Accuracy: 90.30 %\n",
            "Validation Subclass Accuracy: 24.18 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.169\n",
            "Validation Loss: 0.199\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 19.81 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.164\n",
            "Validation Loss: 0.192\n",
            "Validation Superclass Accuracy: 89.21 %\n",
            "Validation Subclass Accuracy: 23.50 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.166\n",
            "Validation Loss: 0.327\n",
            "Validation Superclass Accuracy: 80.74 %\n",
            "Validation Subclass Accuracy: 20.63 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.160\n",
            "Validation Loss: 0.276\n",
            "Validation Superclass Accuracy: 87.02 %\n",
            "Validation Subclass Accuracy: 21.58 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.168\n",
            "Validation Loss: 0.530\n",
            "Validation Superclass Accuracy: 84.56 %\n",
            "Validation Subclass Accuracy: 25.55 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB5"
      ],
      "metadata": {
        "id": "RbGGNsX7Dd2f"
      },
      "id": "RbGGNsX7Dd2f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb5 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "jLur74eUDg5S"
      },
      "id": "jLur74eUDg5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb5, epoch=10)"
      ],
      "metadata": {
        "id": "OnFIPb4IDhAF"
      },
      "id": "OnFIPb4IDhAF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetV2"
      ],
      "metadata": {
        "id": "3hhbCUp8yXx_"
      },
      "id": "3hhbCUp8yXx_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.efficientnet_v2_s(pretrained=True)\n",
        "model = CustomEfficientNetV2(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efv2 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "_zhOIvBvyaPB",
        "outputId": "aa5aa15a-d878-43db-b7dd-13d767209e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_zhOIvBvyaPB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:01<00:00, 63.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efv2, epoch=20)"
      ],
      "metadata": {
        "id": "OowQxSE1zUz-",
        "outputId": "e39604e5-58e1-4b30-99a5-6f2f9353035a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OowQxSE1zUz-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.537\n",
            "Validation Loss: 0.285\n",
            "Validation Superclass Accuracy: 81.28 %\n",
            "Validation Subclass Accuracy: 18.99 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.275\n",
            "Validation Loss: 0.238\n",
            "Validation Superclass Accuracy: 84.15 %\n",
            "Validation Subclass Accuracy: 24.18 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.228\n",
            "Validation Loss: 0.198\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 26.91 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.206\n",
            "Validation Loss: 0.169\n",
            "Validation Superclass Accuracy: 90.03 %\n",
            "Validation Subclass Accuracy: 31.01 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.181\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 89.34 %\n",
            "Validation Subclass Accuracy: 37.30 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.164\n",
            "Validation Loss: 0.169\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 38.25 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.192\n",
            "Validation Superclass Accuracy: 88.52 %\n",
            "Validation Subclass Accuracy: 38.66 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.157\n",
            "Validation Loss: 0.171\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 42.62 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.139\n",
            "Validation Loss: 0.137\n",
            "Validation Superclass Accuracy: 92.21 %\n",
            "Validation Subclass Accuracy: 43.72 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.132\n",
            "Validation Loss: 0.153\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 45.22 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.131\n",
            "Validation Loss: 0.158\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 44.81 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.124\n",
            "Validation Loss: 0.139\n",
            "Validation Superclass Accuracy: 93.03 %\n",
            "Validation Subclass Accuracy: 48.09 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.126\n",
            "Validation Loss: 0.150\n",
            "Validation Superclass Accuracy: 92.62 %\n",
            "Validation Subclass Accuracy: 47.27 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.118\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 46.31 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.112\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 49.73 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.108\n",
            "Validation Loss: 0.175\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 47.95 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.115\n",
            "Validation Loss: 0.154\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 51.37 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.103\n",
            "Validation Loss: 0.145\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 50.68 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.109\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.091\n",
            "Validation Loss: 0.126\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 52.19 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetV2 CrossEntropyLoss"
      ],
      "metadata": {
        "id": "F6z9yo0O6Oif"
      },
      "id": "F6z9yo0O6Oif"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.efficientnet_v2_s(pretrained=True)\n",
        "model = CustomEfficientNetV2(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efv2_celoss = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "J2VDBjB26THB",
        "outputId": "ca1ef56c-e112-4bb5-8224-84d338229aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J2VDBjB26THB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efv2_celoss, epoch=30)"
      ],
      "metadata": {
        "id": "yS9ReWAr6VjO",
        "outputId": "3d8d1b9c-6d3c-4083-9b5a-d27189e2e6a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yS9ReWAr6VjO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 4.430\n",
            "Validation Loss: 4.317\n",
            "Validation Superclass Accuracy: 77.46 %\n",
            "Validation Subclass Accuracy: 25.00 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 2.974\n",
            "Validation Loss: 2.708\n",
            "Validation Superclass Accuracy: 82.24 %\n",
            "Validation Subclass Accuracy: 37.70 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 2.414\n",
            "Validation Loss: 2.162\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 50.55 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 1.970\n",
            "Validation Loss: 1.823\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 56.42 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 1.756\n",
            "Validation Loss: 1.937\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 56.42 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 1.531\n",
            "Validation Loss: 1.706\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 58.74 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 1.575\n",
            "Validation Loss: 3.264\n",
            "Validation Superclass Accuracy: 76.91 %\n",
            "Validation Subclass Accuracy: 35.79 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 2.045\n",
            "Validation Loss: 2.156\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 50.96 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 1.721\n",
            "Validation Loss: 1.726\n",
            "Validation Superclass Accuracy: 90.03 %\n",
            "Validation Subclass Accuracy: 58.88 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 1.460\n",
            "Validation Loss: 1.553\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 62.70 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 1.335\n",
            "Validation Loss: 1.562\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 60.38 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 1.211\n",
            "Validation Loss: 1.541\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 64.07 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 1.138\n",
            "Validation Loss: 1.446\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 63.66 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 1.584\n",
            "Validation Loss: 2.471\n",
            "Validation Superclass Accuracy: 84.97 %\n",
            "Validation Subclass Accuracy: 55.87 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 1.547\n",
            "Validation Loss: 1.667\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 59.84 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 1.472\n",
            "Validation Loss: 3.044\n",
            "Validation Superclass Accuracy: 78.69 %\n",
            "Validation Subclass Accuracy: 40.16 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 1.766\n",
            "Validation Loss: 1.735\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 58.33 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 1.389\n",
            "Validation Loss: 1.837\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 63.11 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 1.193\n",
            "Validation Loss: 1.938\n",
            "Validation Superclass Accuracy: 88.52 %\n",
            "Validation Subclass Accuracy: 58.06 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 1.109\n",
            "Validation Loss: 1.571\n",
            "Validation Superclass Accuracy: 92.49 %\n",
            "Validation Subclass Accuracy: 64.75 %\n",
            "\n",
            "Epoch 21\n",
            "Training loss: 1.049\n",
            "Validation Loss: 1.860\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 58.74 %\n",
            "\n",
            "Epoch 22\n",
            "Training loss: 1.049\n",
            "Validation Loss: 1.658\n",
            "Validation Superclass Accuracy: 90.30 %\n",
            "Validation Subclass Accuracy: 63.93 %\n",
            "\n",
            "Epoch 23\n",
            "Training loss: 0.957\n",
            "Validation Loss: 1.628\n",
            "Validation Superclass Accuracy: 91.39 %\n",
            "Validation Subclass Accuracy: 62.84 %\n",
            "\n",
            "Epoch 24\n",
            "Training loss: 0.895\n",
            "Validation Loss: 1.513\n",
            "Validation Superclass Accuracy: 92.76 %\n",
            "Validation Subclass Accuracy: 66.67 %\n",
            "\n",
            "Epoch 25\n",
            "Training loss: 0.812\n",
            "Validation Loss: 1.557\n",
            "Validation Superclass Accuracy: 91.26 %\n",
            "Validation Subclass Accuracy: 68.03 %\n",
            "\n",
            "Epoch 26\n",
            "Training loss: 0.839\n",
            "Validation Loss: 1.703\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 64.62 %\n",
            "\n",
            "Epoch 27\n",
            "Training loss: 0.862\n",
            "Validation Loss: 1.546\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 64.48 %\n",
            "\n",
            "Epoch 28\n",
            "Training loss: 0.960\n",
            "Validation Loss: 1.620\n",
            "Validation Superclass Accuracy: 91.12 %\n",
            "Validation Subclass Accuracy: 62.84 %\n",
            "\n",
            "Epoch 29\n",
            "Training loss: 0.899\n",
            "Validation Loss: 1.499\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 64.62 %\n",
            "\n",
            "Epoch 30\n",
            "Training loss: 0.776\n",
            "Validation Loss: 1.515\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 66.80 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50"
      ],
      "metadata": {
        "id": "5omYNluLPthV"
      },
      "id": "5omYNluLPthV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "model = CustomResNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_res50 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "Y47e_JHSPu9I"
      },
      "id": "Y47e_JHSPu9I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_res50, epoch=30)"
      ],
      "metadata": {
        "id": "1IrxzQt0PvAu",
        "outputId": "0a1cd9b5-f89d-4a29-c7a0-f90ec1e1e3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1IrxzQt0PvAu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.461\n",
            "Validation Loss: 0.331\n",
            "Validation Superclass Accuracy: 81.01 %\n",
            "Validation Subclass Accuracy: 28.69 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.240\n",
            "Validation Loss: 0.247\n",
            "Validation Superclass Accuracy: 85.52 %\n",
            "Validation Subclass Accuracy: 33.33 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.212\n",
            "Validation Loss: 0.214\n",
            "Validation Superclass Accuracy: 86.75 %\n",
            "Validation Subclass Accuracy: 39.48 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.195\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.66 %\n",
            "Validation Subclass Accuracy: 38.93 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.175\n",
            "Validation Loss: 0.180\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 43.31 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.167\n",
            "Validation Loss: 0.154\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 43.85 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.156\n",
            "Validation Loss: 0.193\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 45.63 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.156\n",
            "Validation Loss: 0.191\n",
            "Validation Superclass Accuracy: 88.25 %\n",
            "Validation Subclass Accuracy: 43.31 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.149\n",
            "Validation Loss: 0.207\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 44.26 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.150\n",
            "Validation Loss: 0.222\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 46.72 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.137\n",
            "Validation Loss: 0.177\n",
            "Validation Superclass Accuracy: 89.07 %\n",
            "Validation Subclass Accuracy: 44.13 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.139\n",
            "Validation Loss: 0.161\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 48.91 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.128\n",
            "Validation Loss: 0.188\n",
            "Validation Superclass Accuracy: 89.21 %\n",
            "Validation Subclass Accuracy: 49.45 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.128\n",
            "Validation Loss: 0.185\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 49.73 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.121\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.118\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 49.45 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.110\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 91.12 %\n",
            "Validation Subclass Accuracy: 50.00 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.115\n",
            "Validation Loss: 0.161\n",
            "Validation Superclass Accuracy: 89.75 %\n",
            "Validation Subclass Accuracy: 46.86 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.116\n",
            "Validation Loss: 0.135\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 53.55 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.112\n",
            "Validation Loss: 0.260\n",
            "Validation Superclass Accuracy: 89.07 %\n",
            "Validation Subclass Accuracy: 48.63 %\n",
            "\n",
            "Epoch 21\n",
            "Training loss: 0.107\n",
            "Validation Loss: 0.162\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 49.59 %\n",
            "\n",
            "Epoch 22\n",
            "Training loss: 0.106\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 23\n",
            "Training loss: 0.110\n",
            "Validation Loss: 0.145\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 50.27 %\n",
            "\n",
            "Epoch 24\n",
            "Training loss: 0.101\n",
            "Validation Loss: 0.156\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 47.68 %\n",
            "\n",
            "Epoch 25\n",
            "Training loss: 0.104\n",
            "Validation Loss: 0.140\n",
            "Validation Superclass Accuracy: 92.76 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 26\n",
            "Training loss: 0.096\n",
            "Validation Loss: 0.151\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 53.96 %\n",
            "\n",
            "Epoch 27\n",
            "Training loss: 0.100\n",
            "Validation Loss: 0.220\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 45.77 %\n",
            "\n",
            "Epoch 28\n",
            "Training loss: 0.099\n",
            "Validation Loss: 0.149\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 53.01 %\n",
            "\n",
            "Epoch 29\n",
            "Training loss: 0.094\n",
            "Validation Loss: 0.160\n",
            "Validation Superclass Accuracy: 90.44 %\n",
            "Validation Subclass Accuracy: 52.87 %\n",
            "\n",
            "Epoch 30\n",
            "Training loss: 0.092\n",
            "Validation Loss: 0.133\n",
            "Validation Superclass Accuracy: 91.67 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "model = CustomResNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_res18 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "UKayAzN9b7xH",
        "outputId": "9fc7fbca-5a9d-4a32-9f3b-a9a659cc8f2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UKayAzN9b7xH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 180MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_res18, epoch=20)"
      ],
      "metadata": {
        "id": "1W37J4jacaP6",
        "outputId": "0b61bfd5-67b8-4b19-91fa-4edee85709f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1W37J4jacaP6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.387\n",
            "Validation Loss: 0.297\n",
            "Validation Superclass Accuracy: 78.28 %\n",
            "Validation Subclass Accuracy: 18.31 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.271\n",
            "Validation Loss: 0.265\n",
            "Validation Superclass Accuracy: 81.42 %\n",
            "Validation Subclass Accuracy: 20.77 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.249\n",
            "Validation Loss: 0.267\n",
            "Validation Superclass Accuracy: 82.10 %\n",
            "Validation Subclass Accuracy: 20.77 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.228\n",
            "Validation Loss: 0.240\n",
            "Validation Superclass Accuracy: 85.11 %\n",
            "Validation Subclass Accuracy: 22.54 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.216\n",
            "Validation Loss: 0.249\n",
            "Validation Superclass Accuracy: 84.43 %\n",
            "Validation Subclass Accuracy: 21.99 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.212\n",
            "Validation Loss: 0.220\n",
            "Validation Superclass Accuracy: 85.93 %\n",
            "Validation Subclass Accuracy: 23.36 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.196\n",
            "Validation Loss: 0.225\n",
            "Validation Superclass Accuracy: 85.25 %\n",
            "Validation Subclass Accuracy: 24.86 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.191\n",
            "Validation Loss: 0.193\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 25.00 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.190\n",
            "Validation Loss: 0.173\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 25.68 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.180\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 25.55 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.177\n",
            "Validation Loss: 0.174\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 29.10 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.173\n",
            "Validation Loss: 0.218\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 27.46 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.171\n",
            "Validation Loss: 0.181\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 27.32 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.155\n",
            "Validation Loss: 0.204\n",
            "Validation Superclass Accuracy: 87.02 %\n",
            "Validation Subclass Accuracy: 27.60 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.222\n",
            "Validation Superclass Accuracy: 85.66 %\n",
            "Validation Subclass Accuracy: 29.51 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.155\n",
            "Validation Loss: 0.204\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 28.42 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 89.75 %\n",
            "Validation Subclass Accuracy: 30.60 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.143\n",
            "Validation Loss: 0.195\n",
            "Validation Superclass Accuracy: 87.70 %\n",
            "Validation Subclass Accuracy: 31.97 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.146\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 33.06 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.145\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 32.65 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnG9Ob7ZchWC"
      },
      "id": "gnG9Ob7ZchWC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Test Data"
      ],
      "metadata": {
        "id": "NPR32fgxcsvO"
      },
      "id": "NPR32fgxcsvO"
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_mbv2, save_to_csv=True, super_name='super_preds_mbv2.csv', sub_name='sub_preds_mbv2.csv', autocoder=True, return_predictions=False)"
      ],
      "metadata": {
        "id": "VpfHLU2Wcz5K"
      },
      "id": "VpfHLU2Wcz5K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efb5, save_to_csv=True, super_name='super_preds_efb5.csv', sub_name='sub_preds_efb5.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "Yx0SFUe0c1kc"
      },
      "id": "Yx0SFUe0c1kc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efb7, save_to_csv=True, super_name='super_preds_efb7.csv', sub_name='sub_preds_efb7.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "qFwKAHZNc1sz"
      },
      "id": "qFwKAHZNc1sz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_res18, save_to_csv=True, super_name='super_preds_res18.csv', sub_name='sub_preds_res18.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "RjEq7Pcnc1zb"
      },
      "id": "RjEq7Pcnc1zb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_res50, save_to_csv=True, super_name='super_preds_res50.csv', sub_name='sub_preds_res50.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "rAxXYY4Rc15V"
      },
      "id": "rAxXYY4Rc15V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efv2, save_to_csv=True, super_name='super_preds_efv2.csv', sub_name='sub_preds_efv2.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "5aqMBOCG5jXE"
      },
      "id": "5aqMBOCG5jXE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efv2_celoss, save_to_csv=True, super_name='super_preds_efv2celoss.csv', sub_name='sub_preds_efv2celoss.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "kjTaux4iBY3z"
      },
      "id": "kjTaux4iBY3z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_df(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['probs'] = df['subclass_probs']\n",
        "    df['probs'] = df['probs'].str.strip('[]').str.split()\n",
        "    df['probs'] = df['probs'].apply(lambda x: [float(i) for i in x[:-1]])\n",
        "    df['Max_Prob'] = df['probs'].apply(max)\n",
        "    df['Target'] = df['probs'].apply(lambda x: x.index(max(x)))\n",
        "    df['Target'] = df['Target'].where(df['Max_Prob'] > threshold, 87)\n",
        "    # print distribution\n",
        "    print(df['Target'].value_counts())\n",
        "    return df"
      ],
      "metadata": {
        "id": "IkBsY_oU5nyO"
      },
      "id": "IkBsY_oU5nyO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_df(df, output_name):\n",
        "    output = pd.DataFrame({'ID': df['image'], 'Target': df['Target']})\n",
        "    output.to_csv(output_name, index=False)\n",
        "    return output"
      ],
      "metadata": {
        "id": "mTC8hxcD5swP"
      },
      "id": "mTC8hxcD5swP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetB7 BCE more data"
      ],
      "metadata": {
        "id": "XzYlWejd-PXc"
      },
      "id": "XzYlWejd-PXc"
    },
    {
      "cell_type": "code",
      "source": [
        "filename='subclass_prediction.csv'\n",
        "df = pd.read_csv(filename)\n",
        "sub_df_transformed = transform_df(df, 0.3)\n",
        "output_df(sub_df_transformed, 'sub_test_effcientNet_moreData.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "kAO2AvjYAKW0",
        "outputId": "d83bd5b5-198d-48da-fa4e-fbe18fb27b9d"
      },
      "id": "kAO2AvjYAKW0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87    11816\n",
            "37      262\n",
            "50      136\n",
            "71       66\n",
            "41       43\n",
            "18       22\n",
            "24       17\n",
            "28       12\n",
            "35        2\n",
            "75        1\n",
            "Name: Target, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ID  Target\n",
              "0          0.jpg      87\n",
              "1          1.jpg      87\n",
              "2          2.jpg      87\n",
              "3          3.jpg      87\n",
              "4          4.jpg      37\n",
              "...          ...     ...\n",
              "12372  12372.jpg      87\n",
              "12373  12373.jpg      87\n",
              "12374  12374.jpg      87\n",
              "12375  12375.jpg      87\n",
              "12376  12376.jpg      87\n",
              "\n",
              "[12377 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12372</th>\n",
              "      <td>12372.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12373</th>\n",
              "      <td>12373.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12374</th>\n",
              "      <td>12374.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12375</th>\n",
              "      <td>12375.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12376</th>\n",
              "      <td>12376.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12377 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-514f9c38-f04a-4174-9b2f-d28aa0c7887a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-514f9c38-f04a-4174-9b2f-d28aa0c7887a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-514f9c38-f04a-4174-9b2f-d28aa0c7887a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df_transformed = transform_df(df, 0.8)\n",
        "output_df(sub_df_transformed, 'sub_test_effcientNet_moreData.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9gjosilo2zHH",
        "outputId": "0e76d6ac-83c3-4f3e-8d02-49cf90f9b4a4"
      },
      "id": "9gjosilo2zHH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4     2728\n",
            "6     1420\n",
            "24    1073\n",
            "2      916\n",
            "57     746\n",
            "37     695\n",
            "21     669\n",
            "50     522\n",
            "75     476\n",
            "71     473\n",
            "30     435\n",
            "65     347\n",
            "62     323\n",
            "72     273\n",
            "52     262\n",
            "68     228\n",
            "41     167\n",
            "26     118\n",
            "36     113\n",
            "51      78\n",
            "28      74\n",
            "43      45\n",
            "7       34\n",
            "18      30\n",
            "77      26\n",
            "70      26\n",
            "12      15\n",
            "25      14\n",
            "9       12\n",
            "64      12\n",
            "35       8\n",
            "84       5\n",
            "13       5\n",
            "63       2\n",
            "78       2\n",
            "34       1\n",
            "38       1\n",
            "49       1\n",
            "17       1\n",
            "15       1\n",
            "Name: Target, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ID  Target\n",
              "0          0.jpg      21\n",
              "1          1.jpg      24\n",
              "2          2.jpg      71\n",
              "3          3.jpg       4\n",
              "4          4.jpg      37\n",
              "...          ...     ...\n",
              "12372  12372.jpg       4\n",
              "12373  12373.jpg      71\n",
              "12374  12374.jpg      57\n",
              "12375  12375.jpg      52\n",
              "12376  12376.jpg      72\n",
              "\n",
              "[12377 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12372</th>\n",
              "      <td>12372.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12373</th>\n",
              "      <td>12373.jpg</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12374</th>\n",
              "      <td>12374.jpg</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12375</th>\n",
              "      <td>12375.jpg</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12376</th>\n",
              "      <td>12376.jpg</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12377 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-63e44535-d154-43b6-af4b-21837f62caf2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63e44535-d154-43b6-af4b-21837f62caf2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-63e44535-d154-43b6-af4b-21837f62caf2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZwCZlq_4f2h"
      },
      "id": "MZwCZlq_4f2h",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}