{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Wukkkinz-0725/animalImage_classification.git"
      ],
      "metadata": {
        "id": "p0Y0iPo8SjIX",
        "outputId": "a0d64266-c85f-4719-9b27-d27a6c825a6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p0Y0iPo8SjIX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'animalImage_classification'...\n",
            "remote: Enumerating objects: 18607, done.\u001b[K\n",
            "remote: Counting objects: 100% (18607/18607), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 18607 (delta 18561), reused 18581 (delta 18549), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18607/18607), 13.80 MiB | 23.90 MiB/s, done.\n",
            "Resolving deltas: 100% (18561/18561), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdj9jVAxjm6v",
        "outputId": "702d8486-ce8b-450c-e7c4-873e621c789b"
      },
      "id": "Cdj9jVAxjm6v",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "S_Q8363gRlIE"
      },
      "id": "S_Q8363gRlIE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./animalImage_classification/Released_Data')"
      ],
      "metadata": {
        "id": "DCG4pGJHR4QO"
      },
      "id": "DCG4pGJHR4QO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "ANiA5CLoC_E2"
      },
      "id": "ANiA5CLoC_E2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
      "metadata": {
        "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c"
      },
      "outputs": [],
      "source": [
        "# Create Dataset class for multilabel classification\n",
        "class MultiClassImageDataset(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.ann_df['image'][idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        super_idx = self.ann_df['superclass_index'][idx]\n",
        "        super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "        sub_idx = self.ann_df['subclass_index'][idx]\n",
        "        sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "class MultiClassImageTestDataset(Dataset):\n",
        "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): # Count files in img_dir\n",
        "        return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = str(idx) + '.jpg'\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_split(dataset, stratify_by='superclass_index'):\n",
        "    from torch.utils.data import Subset\n",
        "    # Extract labels for stratification\n",
        "    labels = np.array(dataset.ann_df[stratify_by])\n",
        "\n",
        "    # Perform stratified split\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=10)\n",
        "    train_idx, val_idx = next(sss.split(np.zeros(len(labels)), labels))\n",
        "\n",
        "    # Create train and validation subsets\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "    return train_subset, val_subset"
      ],
      "metadata": {
        "id": "N_YUkjtNdSLj"
      },
      "id": "N_YUkjtNdSLj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "cifar10_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Filter images evenly across remaining 7 classes\n",
        "class_limit = 1000 // 7  # Approximate number of images per class\n",
        "class_counts = {label: 0 for label in range(10) if label not in [2, 5, 6]}\n",
        "filtered_images = []\n",
        "\n",
        "for image, label in cifar10_dataset:\n",
        "    if label in class_counts and class_counts[label] < class_limit:\n",
        "        filtered_images.append((image, label))\n",
        "        class_counts[label] += 1\n",
        "    if all(count == class_limit for count in class_counts.values()):\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBtFBx_1eZ8r",
        "outputId": "60276536-75a1-4d00-8541-53bb7be37465"
      },
      "id": "DBtFBx_1eZ8r",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read existing data from CSV file or create a new DataFrame if the file doesn't exist\n",
        "csv_file = 'train_data.csv'\n",
        "new_csv_file = 'train_data_v1.csv'\n",
        "existing_df = pd.read_csv(csv_file)\n",
        "DROP_IDX = [534, 589, 1013, 1231, 1274, 1501, 1827, 1922, 2191, 2195, 2197, 2548, 2575, 2578,\n",
        "2690, 3049, 3099, 3100, 3292, 3481, 3702, 3743, 4099, 4565, 4850, 4914, 5039, 5150,\n",
        "5222, 5350, 5557, 5726, 6037, 6262]\n",
        "existing_df.drop(DROP_IDX, axis=0)\n",
        "# Prepare CSV data for new images\n",
        "new_csv_data = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "for i, (image, _) in enumerate(filtered_images, start=6322):\n",
        "    file_name = f'{i}.jpg'\n",
        "    image_path = os.path.join('train_shuffle', file_name)\n",
        "    image = transforms.ToPILImage()(image)\n",
        "    image.save(image_path)\n",
        "\n",
        "    # Update CSV data\n",
        "    new_csv_data['image'].append(file_name)\n",
        "    new_csv_data['superclass_index'].append(3)\n",
        "    new_csv_data['subclass_index'].append(87)\n",
        "\n",
        "new_df = pd.DataFrame(new_csv_data)\n",
        "combined_df = existing_df.append(new_df, ignore_index=True)\n",
        "\n",
        "# Write the combined DataFrame to the CSV file\n",
        "combined_df.to_csv(new_csv_file, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErMMb3UYexxJ",
        "outputId": "3037077d-008d-4d5b-d70c-26e5b430f9d3"
      },
      "id": "ErMMb3UYexxJ",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-167-b25c044e49db>:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  combined_df = existing_df.append(new_df, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "e7398553-8842-4ad8-b348-767921a22482",
      "metadata": {
        "id": "e7398553-8842-4ad8-b348-767921a22482"
      },
      "outputs": [],
      "source": [
        "train_ann_df = pd.read_csv('train_data_v1.csv')\n",
        "super_map_df = pd.read_csv('superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
        "\n",
        "train_img_dir = 'train_shuffle'\n",
        "test_img_dir = 'test_shuffle'\n",
        "\n",
        "image_preprocessing = transforms.Compose([\n",
        "    transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
        "    transforms.RandomVerticalFlip(),    # vertical flip of the image\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),  # random color jitter\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # random translation\n",
        "    transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0)),  # random crop and resize\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # normalization\n",
        "])\n",
        "\n",
        "# Create train and val split\n",
        "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
        "train_dataset, val_dataset = stratified_split(train_dataset)\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=1,\n",
        "                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure it's read in RGB format\n",
        "    return image"
      ],
      "metadata": {
        "id": "PQEB38eRlGaY"
      },
      "id": "PQEB38eRlGaY",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainers"
      ],
      "metadata": {
        "id": "QQYpXee3q_gZ"
      },
      "id": "QQYpXee3q_gZ"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840",
      "metadata": {
        "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            loss += self.criterion(super_outputs, super_labels)\n",
        "            loss += self.criterion(sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                loss += self.criterion(super_outputs, super_labels)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                loss += self.criterion(sub_outputs, sub_labels)\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoderLossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_outputs, super_labels, sub_outputs, sub_labels, decoded, original, alpha=0.5):\n",
        "        classification_loss = nn.CrossEntropyLoss()\n",
        "        reconstruction_loss = nn.MSELoss()\n",
        "\n",
        "        loss_super = classification_loss(super_outputs, super_labels)\n",
        "        loss_sub = classification_loss(sub_outputs, sub_labels)\n",
        "        loss_recon = reconstruction_loss(decoded, original)\n",
        "\n",
        "        return alpha * (loss_super + loss_sub) + (1 - alpha) * loss_recon\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "lY_4CU5znGI_"
      },
      "id": "lY_4CU5znGI_",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCELossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_class_output, super_labels, sub_class_output, sub_labels):\n",
        "        bce_loss = nn.BCEWithLogitsLoss()\n",
        "        super_class_loss = bce_loss(super_class_output, F.one_hot(super_labels, num_classes=4).float())\n",
        "        sub_class_loss = bce_loss(sub_class_output, F.one_hot(sub_labels, num_classes=88).float())\n",
        "        return super_class_loss + sub_class_loss\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "rkXezGQIpTNB"
      },
      "id": "rkXezGQIpTNB",
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "qFI4Pg1xq66R"
      },
      "id": "qFI4Pg1xq66R"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CustomEfficientNet(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        in_features = self.base_model._fc.in_features\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.extract_features(x)\n",
        "\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n"
      ],
      "metadata": {
        "id": "AYqENNBomuNV"
      },
      "id": "AYqENNBomuNV",
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEfficientNetV2(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNetV2, self).__init__()\n",
        "        # Load a pretrained EfficientNetV2-S model\n",
        "        self.base_model = base_model\n",
        "\n",
        "        # EfficientNetV2 uses a head instead of fc for the classifier\n",
        "        in_features = self.base_model.classifier[1].in_features\n",
        "\n",
        "        # Replace the classifier with custom classifiers\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the base model\n",
        "        features = self.base_model.features(x)\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        # Classify into super and sub classes\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n"
      ],
      "metadata": {
        "id": "Xc0bSCmexpif"
      },
      "id": "Xc0bSCmexpif",
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomResNet, self).__init__()\n",
        "        # Load a pretrained ResNet50 model\n",
        "        base_model = base_model\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "        in_features = base_model.fc.in_features\n",
        "        base_model.fc = nn.Identity()  # Remove the original fully connected layer\n",
        "\n",
        "        self.base_model = base_model\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from the base model\n",
        "        features = self.base_model(x)\n",
        "\n",
        "        # Classify into super and sub classes\n",
        "        super_class_output = self.super_class_classifier(features)\n",
        "        sub_class_output = self.sub_class_classifier(features)\n",
        "\n",
        "        return super_class_output, sub_class_output"
      ],
      "metadata": {
        "id": "CPlYDDgvOh8A"
      },
      "id": "CPlYDDgvOh8A",
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetAutoencoder(nn.Module):\n",
        "    def __init__(self, num_super_classes=4, num_sub_classes=88):\n",
        "        super(MobileNetAutoencoder, self).__init__()\n",
        "        self.mobilenet_features = models.mobilenet_v2(pretrained=True).features\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.mobilenet_features,\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(1280, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 32 * 32 * 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(1280, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(1280, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        encoded = torch.flatten(encoded, 1)\n",
        "\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(-1, 3, 32, 32)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(encoded)\n",
        "        sub_class_output = self.sub_class_classifier(encoded)\n",
        "\n",
        "        return super_class_output, sub_class_output, decoded\n"
      ],
      "metadata": {
        "id": "hRad0oE0DPo5"
      },
      "id": "hRad0oE0DPo5",
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(trainer, save_to_csv=False, super_name='super_pred.csv', sub_name='sub_pred.csv', autocoder=False, return_predictions=False):\n",
        "    trainer.model.eval()\n",
        "    if not trainer.test_loader:\n",
        "        raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "    superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "    subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(trainer.test_loader):\n",
        "            inputs, img_name = data[0].to(trainer.device), data[1]\n",
        "            if autocoder:\n",
        "                super_outputs, sub_outputs, _ = trainer.model(inputs)\n",
        "            else:\n",
        "                super_outputs, sub_outputs = trainer.model(inputs)\n",
        "            super_probs = F.softmax(super_outputs, dim=1)\n",
        "            sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "            _, super_predicted = torch.max(super_probs, 1)\n",
        "            _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "            superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "            superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "            superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "            subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "            subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "            subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "    if save_to_csv:\n",
        "        superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "        superclass_df.to_csv(super_name, index=False)\n",
        "\n",
        "        subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "        subclass_df.to_csv(sub_name, index=False)\n",
        "\n",
        "    if return_predictions:\n",
        "        return superclass_predictions, subclass_predictions\n"
      ],
      "metadata": {
        "id": "4Dy5mWxWkBjk"
      },
      "id": "4Dy5mWxWkBjk",
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "7941c289-d9b1-4714-b788-898b3b889f58",
      "metadata": {
        "id": "7941c289-d9b1-4714-b788-898b3b889f58"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_model(trainer, epoch):\n",
        "    for epoch in range(epoch):\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        trainer.train_epoch()\n",
        "        trainer.validate_epoch()\n",
        "        print('')\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "EgLbRQHUrGZg"
      },
      "id": "EgLbRQHUrGZg"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pts2RfVb5gvr"
      },
      "id": "pts2RfVb5gvr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet_V2"
      ],
      "metadata": {
        "id": "6DhDvLx_lqfE"
      },
      "id": "6DhDvLx_lqfE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "model = MobileNetAutoencoder().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_mbv2 = AutoEncoderLossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyOyMdLvloDQ",
        "outputId": "b73195ba-c36b-42d4-9ec9-03472e3efdd2"
      },
      "id": "nyOyMdLvloDQ",
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_mbv2, epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GC1isei-XqH",
        "outputId": "2b893c7b-6244-402d-f0a4-3c86f566973c"
      },
      "id": "8GC1isei-XqH",
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 2.500\n",
            "Validation Loss: 2.108\n",
            "Validation Superclass Accuracy: 81.15 %\n",
            "Validation Subclass Accuracy: 31.56 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 1.990\n",
            "Validation Loss: 1.853\n",
            "Validation Superclass Accuracy: 84.84 %\n",
            "Validation Subclass Accuracy: 40.57 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 1.839\n",
            "Validation Loss: 1.698\n",
            "Validation Superclass Accuracy: 84.02 %\n",
            "Validation Subclass Accuracy: 46.31 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 1.721\n",
            "Validation Loss: 1.582\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 1.636\n",
            "Validation Loss: 1.648\n",
            "Validation Superclass Accuracy: 85.11 %\n",
            "Validation Subclass Accuracy: 50.68 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 1.600\n",
            "Validation Loss: 1.586\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 1.524\n",
            "Validation Loss: 1.600\n",
            "Validation Superclass Accuracy: 88.39 %\n",
            "Validation Subclass Accuracy: 53.01 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 1.508\n",
            "Validation Loss: 1.528\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 53.96 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 1.446\n",
            "Validation Loss: 1.429\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 55.46 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 1.414\n",
            "Validation Loss: 1.500\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 53.83 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_mbv2, save_to_csv=True, super_name='super_preds_mbv2.csv', sub_name='sub_preds_mbv2.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "nwGAVVr8ABZR"
      },
      "id": "nwGAVVr8ABZR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetB7"
      ],
      "metadata": {
        "id": "lEi6lKBrmALB"
      },
      "id": "lEi6lKBrmALB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb7 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38gC7iT-loG_",
        "outputId": "07050e69-0bcd-468e-934b-cf6d6c15103e"
      },
      "id": "38gC7iT-loG_",
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb7, epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws-MwB5DloKa",
        "outputId": "9224b03b-f3fe-4ad7-d4cb-28b50a7207d1"
      },
      "id": "ws-MwB5DloKa",
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.524\n",
            "Validation Loss: 0.774\n",
            "Validation Superclass Accuracy: 58.74 %\n",
            "Validation Subclass Accuracy: 9.29 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.271\n",
            "Validation Loss: 0.319\n",
            "Validation Superclass Accuracy: 82.79 %\n",
            "Validation Subclass Accuracy: 17.21 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.227\n",
            "Validation Loss: 0.219\n",
            "Validation Superclass Accuracy: 87.43 %\n",
            "Validation Subclass Accuracy: 19.13 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.202\n",
            "Validation Loss: 0.257\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 20.36 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.177\n",
            "Validation Loss: 0.182\n",
            "Validation Superclass Accuracy: 90.30 %\n",
            "Validation Subclass Accuracy: 24.18 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.169\n",
            "Validation Loss: 0.199\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 19.81 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.164\n",
            "Validation Loss: 0.192\n",
            "Validation Superclass Accuracy: 89.21 %\n",
            "Validation Subclass Accuracy: 23.50 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.166\n",
            "Validation Loss: 0.327\n",
            "Validation Superclass Accuracy: 80.74 %\n",
            "Validation Subclass Accuracy: 20.63 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.160\n",
            "Validation Loss: 0.276\n",
            "Validation Superclass Accuracy: 87.02 %\n",
            "Validation Subclass Accuracy: 21.58 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.168\n",
            "Validation Loss: 0.530\n",
            "Validation Superclass Accuracy: 84.56 %\n",
            "Validation Subclass Accuracy: 25.55 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB5"
      ],
      "metadata": {
        "id": "RbGGNsX7Dd2f"
      },
      "id": "RbGGNsX7Dd2f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb5 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "jLur74eUDg5S"
      },
      "id": "jLur74eUDg5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb5, epoch=10)"
      ],
      "metadata": {
        "id": "OnFIPb4IDhAF"
      },
      "id": "OnFIPb4IDhAF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetV2"
      ],
      "metadata": {
        "id": "3hhbCUp8yXx_"
      },
      "id": "3hhbCUp8yXx_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.efficientnet_v2_s(pretrained=True)\n",
        "model = CustomEfficientNetV2(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efv2 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "_zhOIvBvyaPB",
        "outputId": "aa5aa15a-d878-43db-b7dd-13d767209e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_zhOIvBvyaPB",
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:01<00:00, 63.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efv2, epoch=20)"
      ],
      "metadata": {
        "id": "OowQxSE1zUz-",
        "outputId": "e39604e5-58e1-4b30-99a5-6f2f9353035a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OowQxSE1zUz-",
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.537\n",
            "Validation Loss: 0.285\n",
            "Validation Superclass Accuracy: 81.28 %\n",
            "Validation Subclass Accuracy: 18.99 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.275\n",
            "Validation Loss: 0.238\n",
            "Validation Superclass Accuracy: 84.15 %\n",
            "Validation Subclass Accuracy: 24.18 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.228\n",
            "Validation Loss: 0.198\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 26.91 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.206\n",
            "Validation Loss: 0.169\n",
            "Validation Superclass Accuracy: 90.03 %\n",
            "Validation Subclass Accuracy: 31.01 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.181\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 89.34 %\n",
            "Validation Subclass Accuracy: 37.30 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.164\n",
            "Validation Loss: 0.169\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 38.25 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.192\n",
            "Validation Superclass Accuracy: 88.52 %\n",
            "Validation Subclass Accuracy: 38.66 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.157\n",
            "Validation Loss: 0.171\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 42.62 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.139\n",
            "Validation Loss: 0.137\n",
            "Validation Superclass Accuracy: 92.21 %\n",
            "Validation Subclass Accuracy: 43.72 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.132\n",
            "Validation Loss: 0.153\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 45.22 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.131\n",
            "Validation Loss: 0.158\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 44.81 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.124\n",
            "Validation Loss: 0.139\n",
            "Validation Superclass Accuracy: 93.03 %\n",
            "Validation Subclass Accuracy: 48.09 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.126\n",
            "Validation Loss: 0.150\n",
            "Validation Superclass Accuracy: 92.62 %\n",
            "Validation Subclass Accuracy: 47.27 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.118\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 46.31 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.112\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 49.73 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.108\n",
            "Validation Loss: 0.175\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 47.95 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.115\n",
            "Validation Loss: 0.154\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 51.37 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.103\n",
            "Validation Loss: 0.145\n",
            "Validation Superclass Accuracy: 90.57 %\n",
            "Validation Subclass Accuracy: 50.68 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.109\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.091\n",
            "Validation Loss: 0.126\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 52.19 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetV2 CrossEntropyLoss"
      ],
      "metadata": {
        "id": "F6z9yo0O6Oif"
      },
      "id": "F6z9yo0O6Oif"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.efficientnet_v2_s(pretrained=True)\n",
        "model = CustomEfficientNetV2(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efv2_celoss = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "J2VDBjB26THB",
        "outputId": "ca1ef56c-e112-4bb5-8224-84d338229aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J2VDBjB26THB",
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efv2_celoss, epoch=30)"
      ],
      "metadata": {
        "id": "yS9ReWAr6VjO",
        "outputId": "3d8d1b9c-6d3c-4083-9b5a-d27189e2e6a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yS9ReWAr6VjO",
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 4.430\n",
            "Validation Loss: 4.317\n",
            "Validation Superclass Accuracy: 77.46 %\n",
            "Validation Subclass Accuracy: 25.00 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 2.974\n",
            "Validation Loss: 2.708\n",
            "Validation Superclass Accuracy: 82.24 %\n",
            "Validation Subclass Accuracy: 37.70 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 2.414\n",
            "Validation Loss: 2.162\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 50.55 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 1.970\n",
            "Validation Loss: 1.823\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 56.42 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 1.756\n",
            "Validation Loss: 1.937\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 56.42 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 1.531\n",
            "Validation Loss: 1.706\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 58.74 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 1.575\n",
            "Validation Loss: 3.264\n",
            "Validation Superclass Accuracy: 76.91 %\n",
            "Validation Subclass Accuracy: 35.79 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 2.045\n",
            "Validation Loss: 2.156\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 50.96 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 1.721\n",
            "Validation Loss: 1.726\n",
            "Validation Superclass Accuracy: 90.03 %\n",
            "Validation Subclass Accuracy: 58.88 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 1.460\n",
            "Validation Loss: 1.553\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 62.70 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 1.335\n",
            "Validation Loss: 1.562\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 60.38 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 1.211\n",
            "Validation Loss: 1.541\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 64.07 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 1.138\n",
            "Validation Loss: 1.446\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 63.66 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 1.584\n",
            "Validation Loss: 2.471\n",
            "Validation Superclass Accuracy: 84.97 %\n",
            "Validation Subclass Accuracy: 55.87 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 1.547\n",
            "Validation Loss: 1.667\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 59.84 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 1.472\n",
            "Validation Loss: 3.044\n",
            "Validation Superclass Accuracy: 78.69 %\n",
            "Validation Subclass Accuracy: 40.16 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 1.766\n",
            "Validation Loss: 1.735\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 58.33 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 1.389\n",
            "Validation Loss: 1.837\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 63.11 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 1.193\n",
            "Validation Loss: 1.938\n",
            "Validation Superclass Accuracy: 88.52 %\n",
            "Validation Subclass Accuracy: 58.06 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 1.109\n",
            "Validation Loss: 1.571\n",
            "Validation Superclass Accuracy: 92.49 %\n",
            "Validation Subclass Accuracy: 64.75 %\n",
            "\n",
            "Epoch 21\n",
            "Training loss: 1.049\n",
            "Validation Loss: 1.860\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 58.74 %\n",
            "\n",
            "Epoch 22\n",
            "Training loss: 1.049\n",
            "Validation Loss: 1.658\n",
            "Validation Superclass Accuracy: 90.30 %\n",
            "Validation Subclass Accuracy: 63.93 %\n",
            "\n",
            "Epoch 23\n",
            "Training loss: 0.957\n",
            "Validation Loss: 1.628\n",
            "Validation Superclass Accuracy: 91.39 %\n",
            "Validation Subclass Accuracy: 62.84 %\n",
            "\n",
            "Epoch 24\n",
            "Training loss: 0.895\n",
            "Validation Loss: 1.513\n",
            "Validation Superclass Accuracy: 92.76 %\n",
            "Validation Subclass Accuracy: 66.67 %\n",
            "\n",
            "Epoch 25\n",
            "Training loss: 0.812\n",
            "Validation Loss: 1.557\n",
            "Validation Superclass Accuracy: 91.26 %\n",
            "Validation Subclass Accuracy: 68.03 %\n",
            "\n",
            "Epoch 26\n",
            "Training loss: 0.839\n",
            "Validation Loss: 1.703\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 64.62 %\n",
            "\n",
            "Epoch 27\n",
            "Training loss: 0.862\n",
            "Validation Loss: 1.546\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 64.48 %\n",
            "\n",
            "Epoch 28\n",
            "Training loss: 0.960\n",
            "Validation Loss: 1.620\n",
            "Validation Superclass Accuracy: 91.12 %\n",
            "Validation Subclass Accuracy: 62.84 %\n",
            "\n",
            "Epoch 29\n",
            "Training loss: 0.899\n",
            "Validation Loss: 1.499\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 64.62 %\n",
            "\n",
            "Epoch 30\n",
            "Training loss: 0.776\n",
            "Validation Loss: 1.515\n",
            "Validation Superclass Accuracy: 92.08 %\n",
            "Validation Subclass Accuracy: 66.80 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50"
      ],
      "metadata": {
        "id": "5omYNluLPthV"
      },
      "id": "5omYNluLPthV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "model = CustomResNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_res50 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "Y47e_JHSPu9I"
      },
      "id": "Y47e_JHSPu9I",
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_res50, epoch=30)"
      ],
      "metadata": {
        "id": "1IrxzQt0PvAu",
        "outputId": "0a1cd9b5-f89d-4a29-c7a0-f90ec1e1e3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1IrxzQt0PvAu",
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.461\n",
            "Validation Loss: 0.331\n",
            "Validation Superclass Accuracy: 81.01 %\n",
            "Validation Subclass Accuracy: 28.69 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.240\n",
            "Validation Loss: 0.247\n",
            "Validation Superclass Accuracy: 85.52 %\n",
            "Validation Subclass Accuracy: 33.33 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.212\n",
            "Validation Loss: 0.214\n",
            "Validation Superclass Accuracy: 86.75 %\n",
            "Validation Subclass Accuracy: 39.48 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.195\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.66 %\n",
            "Validation Subclass Accuracy: 38.93 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.175\n",
            "Validation Loss: 0.180\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 43.31 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.167\n",
            "Validation Loss: 0.154\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 43.85 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.156\n",
            "Validation Loss: 0.193\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 45.63 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.156\n",
            "Validation Loss: 0.191\n",
            "Validation Superclass Accuracy: 88.25 %\n",
            "Validation Subclass Accuracy: 43.31 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.149\n",
            "Validation Loss: 0.207\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 44.26 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.150\n",
            "Validation Loss: 0.222\n",
            "Validation Superclass Accuracy: 86.07 %\n",
            "Validation Subclass Accuracy: 46.72 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.137\n",
            "Validation Loss: 0.177\n",
            "Validation Superclass Accuracy: 89.07 %\n",
            "Validation Subclass Accuracy: 44.13 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.139\n",
            "Validation Loss: 0.161\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 48.91 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.128\n",
            "Validation Loss: 0.188\n",
            "Validation Superclass Accuracy: 89.21 %\n",
            "Validation Subclass Accuracy: 49.45 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.128\n",
            "Validation Loss: 0.185\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 49.73 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.121\n",
            "Validation Loss: 0.148\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.118\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 90.85 %\n",
            "Validation Subclass Accuracy: 49.45 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.110\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 91.12 %\n",
            "Validation Subclass Accuracy: 50.00 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.115\n",
            "Validation Loss: 0.161\n",
            "Validation Superclass Accuracy: 89.75 %\n",
            "Validation Subclass Accuracy: 46.86 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.116\n",
            "Validation Loss: 0.135\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 53.55 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.112\n",
            "Validation Loss: 0.260\n",
            "Validation Superclass Accuracy: 89.07 %\n",
            "Validation Subclass Accuracy: 48.63 %\n",
            "\n",
            "Epoch 21\n",
            "Training loss: 0.107\n",
            "Validation Loss: 0.162\n",
            "Validation Superclass Accuracy: 90.71 %\n",
            "Validation Subclass Accuracy: 49.59 %\n",
            "\n",
            "Epoch 22\n",
            "Training loss: 0.106\n",
            "Validation Loss: 0.155\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 23\n",
            "Training loss: 0.110\n",
            "Validation Loss: 0.145\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 50.27 %\n",
            "\n",
            "Epoch 24\n",
            "Training loss: 0.101\n",
            "Validation Loss: 0.156\n",
            "Validation Superclass Accuracy: 89.62 %\n",
            "Validation Subclass Accuracy: 47.68 %\n",
            "\n",
            "Epoch 25\n",
            "Training loss: 0.104\n",
            "Validation Loss: 0.140\n",
            "Validation Superclass Accuracy: 92.76 %\n",
            "Validation Subclass Accuracy: 51.50 %\n",
            "\n",
            "Epoch 26\n",
            "Training loss: 0.096\n",
            "Validation Loss: 0.151\n",
            "Validation Superclass Accuracy: 91.53 %\n",
            "Validation Subclass Accuracy: 53.96 %\n",
            "\n",
            "Epoch 27\n",
            "Training loss: 0.100\n",
            "Validation Loss: 0.220\n",
            "Validation Superclass Accuracy: 90.16 %\n",
            "Validation Subclass Accuracy: 45.77 %\n",
            "\n",
            "Epoch 28\n",
            "Training loss: 0.099\n",
            "Validation Loss: 0.149\n",
            "Validation Superclass Accuracy: 91.80 %\n",
            "Validation Subclass Accuracy: 53.01 %\n",
            "\n",
            "Epoch 29\n",
            "Training loss: 0.094\n",
            "Validation Loss: 0.160\n",
            "Validation Superclass Accuracy: 90.44 %\n",
            "Validation Subclass Accuracy: 52.87 %\n",
            "\n",
            "Epoch 30\n",
            "Training loss: 0.092\n",
            "Validation Loss: 0.133\n",
            "Validation Superclass Accuracy: 91.67 %\n",
            "Validation Subclass Accuracy: 51.78 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "model = CustomResNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_res18 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "UKayAzN9b7xH",
        "outputId": "9fc7fbca-5a9d-4a32-9f3b-a9a659cc8f2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UKayAzN9b7xH",
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 180MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_res18, epoch=20)"
      ],
      "metadata": {
        "id": "1W37J4jacaP6",
        "outputId": "0b61bfd5-67b8-4b19-91fa-4edee85709f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1W37J4jacaP6",
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.387\n",
            "Validation Loss: 0.297\n",
            "Validation Superclass Accuracy: 78.28 %\n",
            "Validation Subclass Accuracy: 18.31 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.271\n",
            "Validation Loss: 0.265\n",
            "Validation Superclass Accuracy: 81.42 %\n",
            "Validation Subclass Accuracy: 20.77 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.249\n",
            "Validation Loss: 0.267\n",
            "Validation Superclass Accuracy: 82.10 %\n",
            "Validation Subclass Accuracy: 20.77 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.228\n",
            "Validation Loss: 0.240\n",
            "Validation Superclass Accuracy: 85.11 %\n",
            "Validation Subclass Accuracy: 22.54 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.216\n",
            "Validation Loss: 0.249\n",
            "Validation Superclass Accuracy: 84.43 %\n",
            "Validation Subclass Accuracy: 21.99 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.212\n",
            "Validation Loss: 0.220\n",
            "Validation Superclass Accuracy: 85.93 %\n",
            "Validation Subclass Accuracy: 23.36 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.196\n",
            "Validation Loss: 0.225\n",
            "Validation Superclass Accuracy: 85.25 %\n",
            "Validation Subclass Accuracy: 24.86 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.191\n",
            "Validation Loss: 0.193\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 25.00 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.190\n",
            "Validation Loss: 0.173\n",
            "Validation Superclass Accuracy: 88.93 %\n",
            "Validation Subclass Accuracy: 25.68 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.180\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 25.55 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.177\n",
            "Validation Loss: 0.174\n",
            "Validation Superclass Accuracy: 89.89 %\n",
            "Validation Subclass Accuracy: 29.10 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.173\n",
            "Validation Loss: 0.218\n",
            "Validation Superclass Accuracy: 86.34 %\n",
            "Validation Subclass Accuracy: 27.46 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.171\n",
            "Validation Loss: 0.181\n",
            "Validation Superclass Accuracy: 88.11 %\n",
            "Validation Subclass Accuracy: 27.32 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.155\n",
            "Validation Loss: 0.204\n",
            "Validation Superclass Accuracy: 87.02 %\n",
            "Validation Subclass Accuracy: 27.60 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.222\n",
            "Validation Superclass Accuracy: 85.66 %\n",
            "Validation Subclass Accuracy: 29.51 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.155\n",
            "Validation Loss: 0.204\n",
            "Validation Superclass Accuracy: 87.98 %\n",
            "Validation Subclass Accuracy: 28.42 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.159\n",
            "Validation Loss: 0.170\n",
            "Validation Superclass Accuracy: 89.75 %\n",
            "Validation Subclass Accuracy: 30.60 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.143\n",
            "Validation Loss: 0.195\n",
            "Validation Superclass Accuracy: 87.70 %\n",
            "Validation Subclass Accuracy: 31.97 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.146\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 89.48 %\n",
            "Validation Subclass Accuracy: 33.06 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.145\n",
            "Validation Loss: 0.178\n",
            "Validation Superclass Accuracy: 88.80 %\n",
            "Validation Subclass Accuracy: 32.65 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gnG9Ob7ZchWC"
      },
      "id": "gnG9Ob7ZchWC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Test Data"
      ],
      "metadata": {
        "id": "NPR32fgxcsvO"
      },
      "id": "NPR32fgxcsvO"
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_mbv2, save_to_csv=True, super_name='super_preds_mbv2.csv', sub_name='sub_preds_mbv2.csv', autocoder=True, return_predictions=False)"
      ],
      "metadata": {
        "id": "VpfHLU2Wcz5K"
      },
      "id": "VpfHLU2Wcz5K",
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efb5, save_to_csv=True, super_name='super_preds_efb5.csv', sub_name='sub_preds_efb5.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "Yx0SFUe0c1kc"
      },
      "id": "Yx0SFUe0c1kc",
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efb7, save_to_csv=True, super_name='super_preds_efb7.csv', sub_name='sub_preds_efb7.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "qFwKAHZNc1sz"
      },
      "id": "qFwKAHZNc1sz",
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_res18, save_to_csv=True, super_name='super_preds_res18.csv', sub_name='sub_preds_res18.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "RjEq7Pcnc1zb"
      },
      "id": "RjEq7Pcnc1zb",
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_res50, save_to_csv=True, super_name='super_preds_res50.csv', sub_name='sub_preds_res50.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "rAxXYY4Rc15V"
      },
      "id": "rAxXYY4Rc15V",
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efv2, save_to_csv=True, super_name='super_preds_efv2.csv', sub_name='sub_preds_efv2.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "5aqMBOCG5jXE"
      },
      "id": "5aqMBOCG5jXE",
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_efv2_celoss, save_to_csv=True, super_name='super_preds_efv2celoss.csv', sub_name='sub_preds_efv2celoss.csv', return_predictions=False)"
      ],
      "metadata": {
        "id": "kjTaux4iBY3z"
      },
      "id": "kjTaux4iBY3z",
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_df(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['probs'] = df['subclass_probs']\n",
        "    df['probs'] = df['probs'].str.strip('[]').str.split()\n",
        "    df['probs'] = df['probs'].apply(lambda x: [float(i) for i in x[:-1]])\n",
        "    df['Max_Prob'] = df['probs'].apply(max)\n",
        "    df['Target'] = df['probs'].apply(lambda x: x.index(max(x)))\n",
        "    df['Target'] = df['Target'].where(df['Max_Prob'] > threshold, 87)\n",
        "    # print distribution\n",
        "    print(df['Target'].value_counts())\n",
        "    return df"
      ],
      "metadata": {
        "id": "IkBsY_oU5nyO"
      },
      "id": "IkBsY_oU5nyO",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_df(df, output_name):\n",
        "    output = pd.DataFrame({'ID': df['image'], 'Target': df['Target']})\n",
        "    output.to_csv(output_name, index=False)\n",
        "    return output"
      ],
      "metadata": {
        "id": "mTC8hxcD5swP"
      },
      "id": "mTC8hxcD5swP",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetB7 BCE more data"
      ],
      "metadata": {
        "id": "XzYlWejd-PXc"
      },
      "id": "XzYlWejd-PXc"
    },
    {
      "cell_type": "code",
      "source": [
        "filename='subclass_prediction.csv'\n",
        "df = pd.read_csv(filename)\n",
        "sub_df_transformed = transform_df(df, 0.3)\n",
        "output_df(sub_df_transformed, 'sub_test_effcientNet_moreData.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "kAO2AvjYAKW0",
        "outputId": "d83bd5b5-198d-48da-fa4e-fbe18fb27b9d"
      },
      "id": "kAO2AvjYAKW0",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87    11816\n",
            "37      262\n",
            "50      136\n",
            "71       66\n",
            "41       43\n",
            "18       22\n",
            "24       17\n",
            "28       12\n",
            "35        2\n",
            "75        1\n",
            "Name: Target, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ID  Target\n",
              "0          0.jpg      87\n",
              "1          1.jpg      87\n",
              "2          2.jpg      87\n",
              "3          3.jpg      87\n",
              "4          4.jpg      37\n",
              "...          ...     ...\n",
              "12372  12372.jpg      87\n",
              "12373  12373.jpg      87\n",
              "12374  12374.jpg      87\n",
              "12375  12375.jpg      87\n",
              "12376  12376.jpg      87\n",
              "\n",
              "[12377 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12372</th>\n",
              "      <td>12372.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12373</th>\n",
              "      <td>12373.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12374</th>\n",
              "      <td>12374.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12375</th>\n",
              "      <td>12375.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12376</th>\n",
              "      <td>12376.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12377 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-514f9c38-f04a-4174-9b2f-d28aa0c7887a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-514f9c38-f04a-4174-9b2f-d28aa0c7887a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-514f9c38-f04a-4174-9b2f-d28aa0c7887a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df_transformed = transform_df(df, 0.8)\n",
        "output_df(sub_df_transformed, 'sub_test_effcientNet_moreData.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9gjosilo2zHH",
        "outputId": "0e76d6ac-83c3-4f3e-8d02-49cf90f9b4a4"
      },
      "id": "9gjosilo2zHH",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4     2728\n",
            "6     1420\n",
            "24    1073\n",
            "2      916\n",
            "57     746\n",
            "37     695\n",
            "21     669\n",
            "50     522\n",
            "75     476\n",
            "71     473\n",
            "30     435\n",
            "65     347\n",
            "62     323\n",
            "72     273\n",
            "52     262\n",
            "68     228\n",
            "41     167\n",
            "26     118\n",
            "36     113\n",
            "51      78\n",
            "28      74\n",
            "43      45\n",
            "7       34\n",
            "18      30\n",
            "77      26\n",
            "70      26\n",
            "12      15\n",
            "25      14\n",
            "9       12\n",
            "64      12\n",
            "35       8\n",
            "84       5\n",
            "13       5\n",
            "63       2\n",
            "78       2\n",
            "34       1\n",
            "38       1\n",
            "49       1\n",
            "17       1\n",
            "15       1\n",
            "Name: Target, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ID  Target\n",
              "0          0.jpg      21\n",
              "1          1.jpg      24\n",
              "2          2.jpg      71\n",
              "3          3.jpg       4\n",
              "4          4.jpg      37\n",
              "...          ...     ...\n",
              "12372  12372.jpg       4\n",
              "12373  12373.jpg      71\n",
              "12374  12374.jpg      57\n",
              "12375  12375.jpg      52\n",
              "12376  12376.jpg      72\n",
              "\n",
              "[12377 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12372</th>\n",
              "      <td>12372.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12373</th>\n",
              "      <td>12373.jpg</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12374</th>\n",
              "      <td>12374.jpg</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12375</th>\n",
              "      <td>12375.jpg</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12376</th>\n",
              "      <td>12376.jpg</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12377 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-63e44535-d154-43b6-af4b-21837f62caf2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63e44535-d154-43b6-af4b-21837f62caf2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-63e44535-d154-43b6-af4b-21837f62caf2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZwCZlq_4f2h"
      },
      "id": "MZwCZlq_4f2h",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}