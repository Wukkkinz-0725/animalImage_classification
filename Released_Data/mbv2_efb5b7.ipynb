{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Wukkkinz-0725/animalImage_classification.git"
      ],
      "metadata": {
        "id": "p0Y0iPo8SjIX",
        "outputId": "a0d64266-c85f-4719-9b27-d27a6c825a6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p0Y0iPo8SjIX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'animalImage_classification'...\n",
            "remote: Enumerating objects: 18607, done.\u001b[K\n",
            "remote: Counting objects: 100% (18607/18607), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 18607 (delta 18561), reused 18581 (delta 18549), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18607/18607), 13.80 MiB | 23.90 MiB/s, done.\n",
            "Resolving deltas: 100% (18561/18561), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdj9jVAxjm6v",
        "outputId": "702d8486-ce8b-450c-e7c4-873e621c789b"
      },
      "id": "Cdj9jVAxjm6v",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "S_Q8363gRlIE"
      },
      "id": "S_Q8363gRlIE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./animalImage_classification/Released_Data')"
      ],
      "metadata": {
        "id": "DCG4pGJHR4QO"
      },
      "id": "DCG4pGJHR4QO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "ANiA5CLoC_E2"
      },
      "id": "ANiA5CLoC_E2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
      "metadata": {
        "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c"
      },
      "outputs": [],
      "source": [
        "# Create Dataset class for multilabel classification\n",
        "class MultiClassImageDataset(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.ann_df['image'][idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        super_idx = self.ann_df['superclass_index'][idx]\n",
        "        super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "        sub_idx = self.ann_df['subclass_index'][idx]\n",
        "        sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "class MultiClassImageTestDataset(Dataset):\n",
        "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): # Count files in img_dir\n",
        "        return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = str(idx) + '.jpg'\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_split(dataset, stratify_by='superclass_index'):\n",
        "    from torch.utils.data import Subset\n",
        "    # Extract labels for stratification\n",
        "    labels = np.array(dataset.ann_df[stratify_by])\n",
        "\n",
        "    # Perform stratified split\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=10)\n",
        "    train_idx, val_idx = next(sss.split(np.zeros(len(labels)), labels))\n",
        "\n",
        "    # Create train and validation subsets\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "    return train_subset, val_subset"
      ],
      "metadata": {
        "id": "N_YUkjtNdSLj"
      },
      "id": "N_YUkjtNdSLj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "cifar10_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Filter images evenly across remaining 7 classes\n",
        "class_limit = 1000 // 7  # Approximate number of images per class\n",
        "class_counts = {label: 0 for label in range(10) if label not in [2, 5, 6]}\n",
        "filtered_images = []\n",
        "\n",
        "for image, label in cifar10_dataset:\n",
        "    if label in class_counts and class_counts[label] < class_limit:\n",
        "        filtered_images.append((image, label))\n",
        "        class_counts[label] += 1\n",
        "    if all(count == class_limit for count in class_counts.values()):\n",
        "        break"
      ],
      "metadata": {
        "id": "DBtFBx_1eZ8r",
        "outputId": "60276536-75a1-4d00-8541-53bb7be37465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DBtFBx_1eZ8r",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read existing data from CSV file or create a new DataFrame if the file doesn't exist\n",
        "csv_file = 'train_data.csv'\n",
        "new_csv_file = 'train_data_v1.csv'\n",
        "existing_df = pd.read_csv(csv_file)\n",
        "DROP_IDX = [534, 589, 1013, 1231, 1274, 1501, 1827, 1922, 2191, 2195, 2197, 2548, 2575, 2578,\n",
        "2690, 3049, 3099, 3100, 3292, 3481, 3702, 3743, 4099, 4565, 4850, 4914, 5039, 5150,\n",
        "5222, 5350, 5557, 5726, 6037, 6262]\n",
        "existing_df.drop(DROP_IDX, axis=0)\n",
        "# Prepare CSV data for new images\n",
        "new_csv_data = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "for i, (image, _) in enumerate(filtered_images, start=6322):\n",
        "    file_name = f'{i}.jpg'\n",
        "    image_path = os.path.join('train_shuffle', file_name)\n",
        "    image = transforms.ToPILImage()(image)\n",
        "    image.save(image_path)\n",
        "\n",
        "    # Update CSV data\n",
        "    new_csv_data['image'].append(file_name)\n",
        "    new_csv_data['superclass_index'].append(3)\n",
        "    new_csv_data['subclass_index'].append(87)\n",
        "\n",
        "new_df = pd.DataFrame(new_csv_data)\n",
        "combined_df = existing_df.append(new_df, ignore_index=True)\n",
        "\n",
        "# Write the combined DataFrame to the CSV file\n",
        "combined_df.to_csv(new_csv_file, index=False)"
      ],
      "metadata": {
        "id": "ErMMb3UYexxJ",
        "outputId": "3037077d-008d-4d5b-d70c-26e5b430f9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ErMMb3UYexxJ",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-167-b25c044e49db>:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  combined_df = existing_df.append(new_df, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "e7398553-8842-4ad8-b348-767921a22482",
      "metadata": {
        "id": "e7398553-8842-4ad8-b348-767921a22482"
      },
      "outputs": [],
      "source": [
        "train_ann_df = pd.read_csv('train_data_v1.csv')\n",
        "super_map_df = pd.read_csv('superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
        "\n",
        "train_img_dir = 'train_shuffle'\n",
        "test_img_dir = 'test_shuffle'\n",
        "\n",
        "image_preprocessing = transforms.Compose([\n",
        "    transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
        "    transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
        "    transforms.RandomVerticalFlip(),    # vertical flip of the image\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),  # random color jitter\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # random translation\n",
        "    transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0)),  # random crop and resize\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # normalization\n",
        "])\n",
        "\n",
        "# Create train and val split\n",
        "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
        "train_dataset, val_dataset = stratified_split(train_dataset)\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=1,\n",
        "                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure it's read in RGB format\n",
        "    return image"
      ],
      "metadata": {
        "id": "PQEB38eRlGaY"
      },
      "id": "PQEB38eRlGaY",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainers"
      ],
      "metadata": {
        "id": "QQYpXee3q_gZ"
      },
      "id": "QQYpXee3q_gZ"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840",
      "metadata": {
        "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840"
      },
      "outputs": [],
      "source": [
        "# Simple CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "                        nn.Conv2d(32, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "                        nn.Conv2d(64, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.fc1 = nn.Linear(4*4*128, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3a = nn.Linear(128, 4)\n",
        "        self.fc3b = nn.Linear(128, 88)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        super_out = self.fc3a(x)\n",
        "        sub_out = self.fc3b(x)\n",
        "        return super_out, sub_out\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            loss += self.criterion(super_outputs, super_labels)\n",
        "            loss += self.criterion(sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                loss += self.criterion(super_outputs, super_labels)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                loss += self.criterion(sub_outputs, sub_labels)\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoderLossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_outputs, super_labels, sub_outputs, sub_labels, decoded, original, alpha=0.5):\n",
        "        classification_loss = nn.CrossEntropyLoss()\n",
        "        reconstruction_loss = nn.MSELoss()\n",
        "\n",
        "        loss_super = classification_loss(super_outputs, super_labels)\n",
        "        loss_sub = classification_loss(sub_outputs, sub_labels)\n",
        "        loss_recon = reconstruction_loss(decoded, original)\n",
        "\n",
        "        return alpha * (loss_super + loss_sub) + (1 - alpha) * loss_recon\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs, decoded = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels, decoded, inputs)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction_mobilenet_autoencoder.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "lY_4CU5znGI_"
      },
      "id": "lY_4CU5znGI_",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCELossTrainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def custom_loss(self, super_class_output, super_labels, sub_class_output, sub_labels):\n",
        "        bce_loss = nn.BCEWithLogitsLoss()\n",
        "        super_class_loss = bce_loss(super_class_output, F.one_hot(super_labels, num_classes=4).float())\n",
        "        sub_class_loss = bce_loss(sub_class_output, F.one_hot(sub_labels, num_classes=88).float())\n",
        "        return super_class_loss + sub_class_loss\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        self.model.train()\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            super_outputs, sub_outputs = self.model(inputs)\n",
        "            loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "                _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                super_correct += (super_predicted == super_labels).sum().item()\n",
        "                _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                loss = self.custom_loss(super_outputs, super_labels, sub_outputs, sub_labels)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "\n",
        "                super_probs = F.softmax(super_outputs, dim=1)\n",
        "                sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                _, super_predicted = torch.max(super_probs, 1)\n",
        "                _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "                super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "                sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "                superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "                superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "                subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "            superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "            subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions"
      ],
      "metadata": {
        "id": "rkXezGQIpTNB"
      },
      "id": "rkXezGQIpTNB",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "qFI4Pg1xq66R"
      },
      "id": "qFI4Pg1xq66R"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CustomEfficientNet(nn.Module):\n",
        "    def __init__(self, base_model, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        in_features = self.base_model._fc.in_features\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.extract_features(x)\n",
        "\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n"
      ],
      "metadata": {
        "id": "AYqENNBomuNV"
      },
      "id": "AYqENNBomuNV",
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetAutoencoder(nn.Module):\n",
        "    def __init__(self, num_super_classes=4, num_sub_classes=88):\n",
        "        super(MobileNetAutoencoder, self).__init__()\n",
        "        self.mobilenet_features = models.mobilenet_v2(pretrained=True).features\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.mobilenet_features,\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(1280, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 32 * 32 * 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.super_class_classifier = nn.Linear(1280, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(1280, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        encoded = torch.flatten(encoded, 1)\n",
        "\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(-1, 3, 32, 32)\n",
        "\n",
        "        super_class_output = self.super_class_classifier(encoded)\n",
        "        sub_class_output = self.sub_class_classifier(encoded)\n",
        "\n",
        "        return super_class_output, sub_class_output, decoded\n"
      ],
      "metadata": {
        "id": "hRad0oE0DPo5"
      },
      "id": "hRad0oE0DPo5",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(trainer, save_to_csv=False, threshold_super=0.95, threshold_sub=0.95, return_predictions=False):\n",
        "    trainer.model.eval()\n",
        "    if not trainer.test_loader:\n",
        "        raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "    superclass_predictions = {'image': [], 'superclass_index': [], 'superclass_probs': []}\n",
        "    subclass_predictions = {'image': [], 'subclass_index': [], 'subclass_probs': []}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(trainer.test_loader):\n",
        "            inputs, img_name = data[0].to(trainer.device), data[1]\n",
        "\n",
        "            super_outputs, sub_outputs = trainer.model(inputs)\n",
        "\n",
        "            super_probs = F.softmax(super_outputs, dim=1)\n",
        "            sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "            _, super_predicted = torch.max(super_probs, 1)\n",
        "            _, sub_predicted = torch.max(sub_probs, 1)\n",
        "\n",
        "            super_predicted[torch.max(super_probs, 1).values < threshold_super] = 3\n",
        "            sub_predicted[torch.max(sub_probs, 1).values < threshold_sub] = 87\n",
        "\n",
        "            superclass_predictions['superclass_index'].append(super_predicted.item())\n",
        "            superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "            superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "            subclass_predictions['subclass_index'].append(sub_predicted.item())\n",
        "            subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "            subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "    if save_to_csv:\n",
        "        superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "        superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "        subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "        subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "    if return_predictions:\n",
        "        return superclass_predictions, subclass_predictions\n"
      ],
      "metadata": {
        "id": "4Dy5mWxWkBjk"
      },
      "id": "4Dy5mWxWkBjk",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "7941c289-d9b1-4714-b788-898b3b889f58",
      "metadata": {
        "id": "7941c289-d9b1-4714-b788-898b3b889f58"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_model(trainer, epoch):\n",
        "    for epoch in range(epoch):\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        trainer.train_epoch()\n",
        "        trainer.validate_epoch()\n",
        "        print('')\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "EgLbRQHUrGZg"
      },
      "id": "EgLbRQHUrGZg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet_V2"
      ],
      "metadata": {
        "id": "6DhDvLx_lqfE"
      },
      "id": "6DhDvLx_lqfE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "model = MobileNetAutoencoder().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_mbv2 = AutoEncoderLossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "nyOyMdLvloDQ",
        "outputId": "9891d276-f910-478b-dfa5-a72c33afc80a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nyOyMdLvloDQ",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_mbv2, epoch=20)"
      ],
      "metadata": {
        "id": "8GC1isei-XqH",
        "outputId": "e4f64ddd-8473-464a-d44c-3093bfb47146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        }
      },
      "id": "8GC1isei-XqH",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 2.269\n",
            "Validation Loss: 2.077\n",
            "Validation Superclass Accuracy: 77.58 %\n",
            "Validation Subclass Accuracy: 39.59 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 2.082\n",
            "Validation Loss: 2.016\n",
            "Validation Superclass Accuracy: 76.82 %\n",
            "Validation Subclass Accuracy: 41.09 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 2.061\n",
            "Validation Loss: 1.951\n",
            "Validation Superclass Accuracy: 78.76 %\n",
            "Validation Subclass Accuracy: 43.35 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 2.001\n",
            "Validation Loss: 1.976\n",
            "Validation Superclass Accuracy: 78.11 %\n",
            "Validation Subclass Accuracy: 42.06 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 2.209\n",
            "Validation Loss: 2.299\n",
            "Validation Superclass Accuracy: 67.60 %\n",
            "Validation Subclass Accuracy: 41.20 %\n",
            "\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-f818aa312871>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_mbv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-0fe332a6837e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-487078329326>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ec2dfb3130ce>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \"\"\"\n\u001b[1;32m    271\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(trainer_mbv2, save_to_csv=True, threshold_super=0.9, threshold_sub=0.95, return_predictions=False)"
      ],
      "metadata": {
        "id": "nwGAVVr8ABZR"
      },
      "id": "nwGAVVr8ABZR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetB7"
      ],
      "metadata": {
        "id": "lEi6lKBrmALB"
      },
      "id": "lEi6lKBrmALB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb7 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "38gC7iT-loG_",
        "outputId": "1bb13915-6dff-4f4e-a36e-c1a2cc0cdbf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "38gC7iT-loG_",
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb7, epoch=20)"
      ],
      "metadata": {
        "id": "6GqbysvQF5xw",
        "outputId": "ff41ab45-4945-4804-d7f9-7d7814e7b3c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6GqbysvQF5xw",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.433\n",
            "Validation Loss: 0.825\n",
            "Validation Superclass Accuracy: 37.77 %\n",
            "Validation Subclass Accuracy: 22.00 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.252\n",
            "Validation Loss: 0.251\n",
            "Validation Superclass Accuracy: 85.94 %\n",
            "Validation Subclass Accuracy: 33.80 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.208\n",
            "Validation Loss: 0.214\n",
            "Validation Superclass Accuracy: 86.59 %\n",
            "Validation Subclass Accuracy: 32.94 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.178\n",
            "Validation Loss: 0.217\n",
            "Validation Superclass Accuracy: 87.77 %\n",
            "Validation Subclass Accuracy: 36.27 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.175\n",
            "Validation Loss: 0.203\n",
            "Validation Superclass Accuracy: 88.73 %\n",
            "Validation Subclass Accuracy: 33.37 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb7, epoch=20)"
      ],
      "metadata": {
        "id": "ws-MwB5DloKa",
        "outputId": "7eddfe46-90eb-4f8b-f32b-55592891f916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ws-MwB5DloKa",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.464\n",
            "Validation Loss: 0.528\n",
            "Validation Superclass Accuracy: 67.38 %\n",
            "Validation Subclass Accuracy: 29.72 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.307\n",
            "Validation Loss: 0.289\n",
            "Validation Superclass Accuracy: 82.62 %\n",
            "Validation Subclass Accuracy: 33.80 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.276\n",
            "Validation Loss: 0.262\n",
            "Validation Superclass Accuracy: 84.44 %\n",
            "Validation Subclass Accuracy: 34.12 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.256\n",
            "Validation Loss: 0.241\n",
            "Validation Superclass Accuracy: 83.91 %\n",
            "Validation Subclass Accuracy: 36.80 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.238\n",
            "Validation Loss: 0.216\n",
            "Validation Superclass Accuracy: 86.05 %\n",
            "Validation Subclass Accuracy: 37.88 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB5"
      ],
      "metadata": {
        "id": "RbGGNsX7Dd2f"
      },
      "id": "RbGGNsX7Dd2f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "base_model = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "model = CustomEfficientNet(base_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "trainer_efb5 = BCELossTrainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "jLur74eUDg5S",
        "outputId": "2987a168-2dd7-4204-c7d6-0a3136b0e928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jLur74eUDg5S",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(trainer_efb5, epoch=35)"
      ],
      "metadata": {
        "id": "OnFIPb4IDhAF",
        "outputId": "e86a6c2f-ce45-43db-eb27-f2be4bc29afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "OnFIPb4IDhAF",
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 0.451\n",
            "Validation Loss: 0.410\n",
            "Validation Superclass Accuracy: 66.31 %\n",
            "Validation Subclass Accuracy: 32.40 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 0.301\n",
            "Validation Loss: 0.278\n",
            "Validation Superclass Accuracy: 81.22 %\n",
            "Validation Subclass Accuracy: 35.09 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 0.318\n",
            "Validation Loss: 0.311\n",
            "Validation Superclass Accuracy: 79.29 %\n",
            "Validation Subclass Accuracy: 36.48 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 0.289\n",
            "Validation Loss: 0.272\n",
            "Validation Superclass Accuracy: 80.69 %\n",
            "Validation Subclass Accuracy: 36.27 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 0.279\n",
            "Validation Loss: 0.286\n",
            "Validation Superclass Accuracy: 81.33 %\n",
            "Validation Subclass Accuracy: 34.76 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 0.383\n",
            "Validation Loss: 0.421\n",
            "Validation Superclass Accuracy: 67.27 %\n",
            "Validation Subclass Accuracy: 34.23 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.470\n",
            "Validation Loss: 0.525\n",
            "Validation Superclass Accuracy: 53.43 %\n",
            "Validation Subclass Accuracy: 30.90 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.446\n",
            "Validation Loss: 0.426\n",
            "Validation Superclass Accuracy: 64.59 %\n",
            "Validation Subclass Accuracy: 32.40 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.440\n",
            "Validation Loss: 0.494\n",
            "Validation Superclass Accuracy: 56.87 %\n",
            "Validation Subclass Accuracy: 31.12 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.504\n",
            "Validation Loss: 0.505\n",
            "Validation Superclass Accuracy: 56.12 %\n",
            "Validation Subclass Accuracy: 32.40 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.489\n",
            "Validation Loss: 0.483\n",
            "Validation Superclass Accuracy: 58.80 %\n",
            "Validation Subclass Accuracy: 32.94 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.484\n",
            "Validation Loss: 0.493\n",
            "Validation Superclass Accuracy: 56.55 %\n",
            "Validation Subclass Accuracy: 31.12 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.531\n",
            "Validation Loss: 0.503\n",
            "Validation Superclass Accuracy: 54.94 %\n",
            "Validation Subclass Accuracy: 32.08 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.519\n",
            "Validation Loss: 0.498\n",
            "Validation Superclass Accuracy: 56.22 %\n",
            "Validation Subclass Accuracy: 32.94 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.516\n",
            "Validation Loss: 0.482\n",
            "Validation Superclass Accuracy: 57.30 %\n",
            "Validation Subclass Accuracy: 32.19 %\n",
            "\n",
            "Epoch 16\n",
            "Training loss: 0.502\n",
            "Validation Loss: 0.491\n",
            "Validation Superclass Accuracy: 56.01 %\n",
            "Validation Subclass Accuracy: 32.30 %\n",
            "\n",
            "Epoch 17\n",
            "Training loss: 0.517\n",
            "Validation Loss: 0.485\n",
            "Validation Superclass Accuracy: 56.33 %\n",
            "Validation Subclass Accuracy: 32.30 %\n",
            "\n",
            "Epoch 18\n",
            "Training loss: 0.493\n",
            "Validation Loss: 0.469\n",
            "Validation Superclass Accuracy: 57.30 %\n",
            "Validation Subclass Accuracy: 32.83 %\n",
            "\n",
            "Epoch 19\n",
            "Training loss: 0.481\n",
            "Validation Loss: 0.684\n",
            "Validation Superclass Accuracy: 46.89 %\n",
            "Validation Subclass Accuracy: 31.76 %\n",
            "\n",
            "Epoch 20\n",
            "Training loss: 0.533\n",
            "Validation Loss: 0.563\n",
            "Validation Superclass Accuracy: 46.46 %\n",
            "Validation Subclass Accuracy: 31.76 %\n",
            "\n",
            "Epoch 21\n",
            "Training loss: 0.511\n",
            "Validation Loss: 0.499\n",
            "Validation Superclass Accuracy: 54.72 %\n",
            "Validation Subclass Accuracy: 31.97 %\n",
            "\n",
            "Epoch 22\n",
            "Training loss: 0.518\n",
            "Validation Loss: 0.501\n",
            "Validation Superclass Accuracy: 55.58 %\n",
            "Validation Subclass Accuracy: 33.05 %\n",
            "\n",
            "Epoch 23\n",
            "Training loss: 0.504\n",
            "Validation Loss: 0.513\n",
            "Validation Superclass Accuracy: 53.76 %\n",
            "Validation Subclass Accuracy: 32.08 %\n",
            "\n",
            "Epoch 24\n",
            "Training loss: 0.506\n",
            "Validation Loss: 0.505\n",
            "Validation Superclass Accuracy: 53.97 %\n",
            "Validation Subclass Accuracy: 32.40 %\n",
            "\n",
            "Epoch 25\n",
            "Training loss: 0.502\n",
            "Validation Loss: 0.497\n",
            "Validation Superclass Accuracy: 54.40 %\n",
            "Validation Subclass Accuracy: 32.62 %\n",
            "\n",
            "Epoch 26\n",
            "Training loss: 0.487\n",
            "Validation Loss: 0.483\n",
            "Validation Superclass Accuracy: 54.51 %\n",
            "Validation Subclass Accuracy: 31.97 %\n",
            "\n",
            "Epoch 27\n",
            "Training loss: 0.481\n",
            "Validation Loss: 0.487\n",
            "Validation Superclass Accuracy: 57.40 %\n",
            "Validation Subclass Accuracy: 32.40 %\n",
            "\n",
            "Epoch 28\n",
            "Training loss: 0.467\n",
            "Validation Loss: 0.473\n",
            "Validation Superclass Accuracy: 58.91 %\n",
            "Validation Subclass Accuracy: 32.19 %\n",
            "\n",
            "Epoch 29\n",
            "Training loss: 0.482\n",
            "Validation Loss: 0.486\n",
            "Validation Superclass Accuracy: 55.26 %\n",
            "Validation Subclass Accuracy: 32.51 %\n",
            "\n",
            "Epoch 30\n",
            "Training loss: 0.471\n",
            "Validation Loss: 0.463\n",
            "Validation Superclass Accuracy: 61.37 %\n",
            "Validation Subclass Accuracy: 32.19 %\n",
            "\n",
            "Epoch 31\n",
            "Training loss: 0.474\n",
            "Validation Loss: 0.470\n",
            "Validation Superclass Accuracy: 63.20 %\n",
            "Validation Subclass Accuracy: 32.73 %\n",
            "\n",
            "Epoch 32\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-28f8b58da010>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_efb5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-140-f1a86651b1f6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainer, epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-16364bd7dec8>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0msuper_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-161-a790033b8df6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpooled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# scale drop connect_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Pointwise Convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_df(df, threshold):\n",
        "    df = df.copy()\n",
        "    df['probs'] = df['subclass_probs']\n",
        "    df['probs'] = df['probs'].str.strip('[]').str.split()\n",
        "    df['probs'] = df['probs'].apply(lambda x: [float(i) for i in x[:-1]])\n",
        "    df['Max_Prob'] = df['probs'].apply(max)\n",
        "    df['Target'] = df['probs'].apply(lambda x: x.index(max(x)))\n",
        "    df['Target'] = df['Target'].where(df['Max_Prob'] > threshold, 87)\n",
        "    # print distribution\n",
        "    print(df['Target'].value_counts())\n",
        "    return df"
      ],
      "metadata": {
        "id": "IkBsY_oU5nyO"
      },
      "id": "IkBsY_oU5nyO",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_df(df, output_name):\n",
        "    output = pd.DataFrame({'ID': df['image'], 'Target': df['Target']})\n",
        "    output.to_csv(output_name, index=False)\n",
        "    return output"
      ],
      "metadata": {
        "id": "mTC8hxcD5swP"
      },
      "id": "mTC8hxcD5swP",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffcientNetB7 BCE more data"
      ],
      "metadata": {
        "id": "XzYlWejd-PXc"
      },
      "id": "XzYlWejd-PXc"
    },
    {
      "cell_type": "code",
      "source": [
        "filename='subclass_prediction.csv'\n",
        "df = pd.read_csv(filename)\n",
        "sub_df_transformed = transform_df(df, 0.3)\n",
        "output_df(sub_df_transformed, 'sub_test_effcientNet_moreData.csv')"
      ],
      "metadata": {
        "id": "kAO2AvjYAKW0",
        "outputId": "d83bd5b5-198d-48da-fa4e-fbe18fb27b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "id": "kAO2AvjYAKW0",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87    11816\n",
            "37      262\n",
            "50      136\n",
            "71       66\n",
            "41       43\n",
            "18       22\n",
            "24       17\n",
            "28       12\n",
            "35        2\n",
            "75        1\n",
            "Name: Target, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ID  Target\n",
              "0          0.jpg      87\n",
              "1          1.jpg      87\n",
              "2          2.jpg      87\n",
              "3          3.jpg      87\n",
              "4          4.jpg      37\n",
              "...          ...     ...\n",
              "12372  12372.jpg      87\n",
              "12373  12373.jpg      87\n",
              "12374  12374.jpg      87\n",
              "12375  12375.jpg      87\n",
              "12376  12376.jpg      87\n",
              "\n",
              "[12377 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12372</th>\n",
              "      <td>12372.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12373</th>\n",
              "      <td>12373.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12374</th>\n",
              "      <td>12374.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12375</th>\n",
              "      <td>12375.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12376</th>\n",
              "      <td>12376.jpg</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12377 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-253ff23b-f922-4c06-bdbd-d4b7f1c39f6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-514f9c38-f04a-4174-9b2f-d28aa0c7887a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-514f9c38-f04a-4174-9b2f-d28aa0c7887a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-514f9c38-f04a-4174-9b2f-d28aa0c7887a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df_transformed = transform_df(df, 0.8)\n",
        "output_df(sub_df_transformed, 'sub_test_effcientNet_moreData.csv')"
      ],
      "metadata": {
        "id": "9gjosilo2zHH",
        "outputId": "0e76d6ac-83c3-4f3e-8d02-49cf90f9b4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "9gjosilo2zHH",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4     2728\n",
            "6     1420\n",
            "24    1073\n",
            "2      916\n",
            "57     746\n",
            "37     695\n",
            "21     669\n",
            "50     522\n",
            "75     476\n",
            "71     473\n",
            "30     435\n",
            "65     347\n",
            "62     323\n",
            "72     273\n",
            "52     262\n",
            "68     228\n",
            "41     167\n",
            "26     118\n",
            "36     113\n",
            "51      78\n",
            "28      74\n",
            "43      45\n",
            "7       34\n",
            "18      30\n",
            "77      26\n",
            "70      26\n",
            "12      15\n",
            "25      14\n",
            "9       12\n",
            "64      12\n",
            "35       8\n",
            "84       5\n",
            "13       5\n",
            "63       2\n",
            "78       2\n",
            "34       1\n",
            "38       1\n",
            "49       1\n",
            "17       1\n",
            "15       1\n",
            "Name: Target, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ID  Target\n",
              "0          0.jpg      21\n",
              "1          1.jpg      24\n",
              "2          2.jpg      71\n",
              "3          3.jpg       4\n",
              "4          4.jpg      37\n",
              "...          ...     ...\n",
              "12372  12372.jpg       4\n",
              "12373  12373.jpg      71\n",
              "12374  12374.jpg      57\n",
              "12375  12375.jpg      52\n",
              "12376  12376.jpg      72\n",
              "\n",
              "[12377 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12372</th>\n",
              "      <td>12372.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12373</th>\n",
              "      <td>12373.jpg</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12374</th>\n",
              "      <td>12374.jpg</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12375</th>\n",
              "      <td>12375.jpg</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12376</th>\n",
              "      <td>12376.jpg</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12377 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6cbbd026-56b8-4bd1-9fa8-bb0ada3f03c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-63e44535-d154-43b6-af4b-21837f62caf2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63e44535-d154-43b6-af4b-21837f62caf2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-63e44535-d154-43b6-af4b-21837f62caf2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZwCZlq_4f2h"
      },
      "id": "MZwCZlq_4f2h",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}