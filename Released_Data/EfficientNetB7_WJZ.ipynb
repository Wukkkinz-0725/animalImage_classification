{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Wukkkinz-0725/animalImage_classification.git"
      ],
      "metadata": {
        "id": "p0Y0iPo8SjIX",
        "outputId": "88e70bf4-240a-4d94-aa38-c55002d38ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p0Y0iPo8SjIX",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'animalImage_classification'...\n",
            "remote: Enumerating objects: 18600, done.\u001b[K\n",
            "remote: Counting objects: 100% (18600/18600), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 18600 (delta 18556), reused 18582 (delta 18549), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18600/18600), 13.78 MiB | 7.52 MiB/s, done.\n",
            "Resolving deltas: 100% (18556/18556), done.\n",
            "Updating files: 100% (18712/18712), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q efficientnet_pytorch"
      ],
      "metadata": {
        "id": "Cdj9jVAxjm6v",
        "outputId": "36ef6f2a-ac67-4a5c-b788-f5ef4e3da962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cdj9jVAxjm6v",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "S_Q8363gRlIE"
      },
      "id": "S_Q8363gRlIE",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./animalImage_classification/Released_Data')"
      ],
      "metadata": {
        "id": "DCG4pGJHR4QO"
      },
      "id": "DCG4pGJHR4QO",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "ANiA5CLoC_E2"
      },
      "id": "ANiA5CLoC_E2"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
      "metadata": {
        "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c"
      },
      "outputs": [],
      "source": [
        "# Create Dataset class for multilabel classification\n",
        "class MultiClassImageDataset(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.ann_df['image'][idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        super_idx = self.ann_df['superclass_index'][idx]\n",
        "        super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "        sub_idx = self.ann_df['subclass_index'][idx]\n",
        "        sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "class MultiClassImageTestDataset(Dataset):\n",
        "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): # Count files in img_dir\n",
        "        return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = str(idx) + '.jpg'\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "e7398553-8842-4ad8-b348-767921a22482",
      "metadata": {
        "id": "e7398553-8842-4ad8-b348-767921a22482"
      },
      "outputs": [],
      "source": [
        "train_ann_df = pd.read_csv('train_data.csv')\n",
        "super_map_df = pd.read_csv('superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv('subclass_mapping.csv')\n",
        "\n",
        "train_img_dir = 'train_shuffle'\n",
        "test_img_dir = 'test_shuffle'\n",
        "\n",
        "image_preprocessing = transforms.Compose([\n",
        "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
        "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create train and val split\n",
        "train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n",
        "train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=1,\n",
        "                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_transform_single_image(image_path, transform):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure it's read in RGB format\n",
        "    image = transform(image)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "PQEB38eRlGaY"
      },
      "id": "PQEB38eRlGaY",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840",
      "metadata": {
        "id": "bf33a131-0c66-40dc-b8d4-ba5d0f840840"
      },
      "outputs": [],
      "source": [
        "# Simple CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32, 32, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "                        nn.Conv2d(32, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64, 64, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "                        nn.Conv2d(64, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128, 128, 3, padding='same'),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                      )\n",
        "\n",
        "        self.fc1 = nn.Linear(4*4*128, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3a = nn.Linear(128, 4)\n",
        "        self.fc3b = nn.Linear(128, 88)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        super_out = self.fc3a(x)\n",
        "        sub_out = self.fc3b(x)\n",
        "        return super_out, sub_out\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda', train_super=True, train_sub=True):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "        self.train_super = train_super\n",
        "        self.train_sub = train_sub\n",
        "\n",
        "    def train_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            if self.train_super and self.train_sub:\n",
        "                super_outputs, sub_outputs = self.model(inputs)\n",
        "            elif self.train_super:\n",
        "                super_outputs = self.model(inputs)\n",
        "            else:\n",
        "                sub_outputs = self.model(inputs)\n",
        "            loss = 0\n",
        "            if self.train_super:\n",
        "                loss += self.criterion(super_outputs, super_labels)\n",
        "            if self.train_sub:\n",
        "                loss += self.criterion(sub_outputs, sub_labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Training loss: {running_loss / len(self.train_loader):.3f}')\n",
        "\n",
        "    def validate_epoch(self):\n",
        "        super_correct, sub_correct, total = 0, 0, 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.val_loader):\n",
        "                inputs, super_labels, sub_labels = data[0].to(self.device), data[1].to(self.device), data[3].to(self.device)\n",
        "\n",
        "                if self.train_super and self.train_sub:\n",
        "                    super_outputs, sub_outputs = self.model(inputs)\n",
        "                elif self.train_super:\n",
        "                    super_outputs = self.model(inputs)\n",
        "                else:\n",
        "                    sub_outputs = self.model(inputs)\n",
        "                loss = 0\n",
        "                if self.train_super:\n",
        "                    loss += self.criterion(super_outputs, super_labels)\n",
        "                    _, super_predicted = torch.max(super_outputs.data, 1)\n",
        "                    super_correct += (super_predicted == super_labels).sum().item()\n",
        "                if self.train_sub:\n",
        "                    loss += self.criterion(sub_outputs, sub_labels)\n",
        "                    _, sub_predicted = torch.max(sub_outputs.data, 1)\n",
        "                    sub_correct += (sub_predicted == sub_labels).sum().item()\n",
        "                total += super_labels.size(0)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        print(f'Validation Loss: {running_loss / len(self.val_loader):.3f}')\n",
        "        if self.train_super:\n",
        "            print(f'Validation Superclass Accuracy: {100 * super_correct / total:.2f} %')\n",
        "        if self.train_sub:\n",
        "            print(f'Validation Subclass Accuracy: {100 * sub_correct / total:.2f} %')\n",
        "\n",
        "    def test(self, save_to_csv=False, return_predictions=False):\n",
        "        self.model.eval()\n",
        "        if not self.test_loader:\n",
        "            raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "        superclass_predictions = {'image': [], 'superclass_index': []}\n",
        "        subclass_predictions = {'image': [], 'subclass_index': []}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(self.test_loader):\n",
        "                inputs, img_name = data[0].to(self.device), data[1]\n",
        "\n",
        "                if self.train_super and self.train_sub:\n",
        "                    super_outputs, sub_outputs = self.model(inputs)\n",
        "                elif self.train_super:\n",
        "                    super_outputs = self.model(inputs)\n",
        "                    sub_outputs = None\n",
        "                elif self.train_sub:\n",
        "                    super_outputs = None\n",
        "                    sub_outputs = self.model(inputs)\n",
        "                else:\n",
        "                    continue  # Skip if neither superclass nor subclass is trained\n",
        "\n",
        "                if self.train_super:\n",
        "                    super_probs = F.softmax(super_outputs, dim=1)\n",
        "                    superclass_predictions['superclass_probs'].append(super_probs.cpu().numpy())\n",
        "                    superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "                if self.train_sub:\n",
        "                    sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "                    subclass_predictions['subclass_probs'].append(sub_probs.cpu().numpy())\n",
        "                    subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if save_to_csv:\n",
        "            if self.train_super:\n",
        "                superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "                superclass_df.to_csv('superclass_prediction.csv', index=False)\n",
        "\n",
        "            if self.train_sub:\n",
        "                subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "                subclass_df.to_csv('subclass_prediction.csv', index=False)\n",
        "\n",
        "        if return_predictions:\n",
        "            return superclass_predictions, subclass_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CustomEfficientNetB7(nn.Module):\n",
        "    def __init__(self, num_super_classes=4, num_sub_classes=88):\n",
        "        super(CustomEfficientNetB7, self).__init__()\n",
        "        # 加载预训练的EfficientNet-B7模型\n",
        "        self.base_model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "\n",
        "        # 获取原始最后一层的输入特征数\n",
        "        in_features = self.base_model._fc.in_features\n",
        "\n",
        "        # 为超类和子类定义分类头\n",
        "        self.super_class_classifier = nn.Linear(in_features, num_super_classes)\n",
        "        self.sub_class_classifier = nn.Linear(in_features, num_sub_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 从基础模型提取特征\n",
        "        features = self.base_model.extract_features(x)\n",
        "\n",
        "        # 全局平均池化\n",
        "        pooled_features = F.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
        "\n",
        "        # 分类到超类和子类\n",
        "        super_class_output = self.super_class_classifier(pooled_features)\n",
        "        sub_class_output = self.sub_class_classifier(pooled_features)\n",
        "\n",
        "        return super_class_output, sub_class_output\n",
        "\n",
        "# 使用BCE损失函数\n",
        "def custom_loss(super_class_output, super_labels, sub_class_output, sub_labels):\n",
        "    bce_loss = nn.BCEWithLogitsLoss()\n",
        "    super_class_loss = bce_loss(super_class_output, F.one_hot(super_labels, num_classes=4).float())\n",
        "    sub_class_loss = bce_loss(sub_class_output, F.one_hot(sub_labels, num_classes=88).float())\n",
        "    return super_class_loss + sub_class_loss\n"
      ],
      "metadata": {
        "id": "AYqENNBomuNV"
      },
      "id": "AYqENNBomuNV",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1",
      "metadata": {
        "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1",
        "outputId": "830a6e17-55c4-4edc-a845-d51eb4658513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b7\n"
          ]
        }
      ],
      "source": [
        "# Init model and trainer\n",
        "device = 'cuda'\n",
        "model = CustomEfficientNetB7().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "7941c289-d9b1-4714-b788-898b3b889f58",
      "metadata": {
        "id": "7941c289-d9b1-4714-b788-898b3b889f58",
        "outputId": "10a3c9ac-4d2e-457f-e5f3-88d54cbe8768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Training loss: 3.966\n",
            "Validation Loss: 2.979\n",
            "Validation Superclass Accuracy: 89.08 %\n",
            "Validation Subclass Accuracy: 31.96 %\n",
            "\n",
            "Epoch 2\n",
            "Training loss: 2.425\n",
            "Validation Loss: 2.335\n",
            "Validation Superclass Accuracy: 92.41 %\n",
            "Validation Subclass Accuracy: 45.25 %\n",
            "\n",
            "Epoch 3\n",
            "Training loss: 1.856\n",
            "Validation Loss: 2.063\n",
            "Validation Superclass Accuracy: 92.09 %\n",
            "Validation Subclass Accuracy: 49.05 %\n",
            "\n",
            "Epoch 4\n",
            "Training loss: 1.542\n",
            "Validation Loss: 1.841\n",
            "Validation Superclass Accuracy: 93.35 %\n",
            "Validation Subclass Accuracy: 55.70 %\n",
            "\n",
            "Epoch 5\n",
            "Training loss: 1.219\n",
            "Validation Loss: 1.783\n",
            "Validation Superclass Accuracy: 94.94 %\n",
            "Validation Subclass Accuracy: 57.59 %\n",
            "\n",
            "Epoch 6\n",
            "Training loss: 1.083\n",
            "Validation Loss: 1.725\n",
            "Validation Superclass Accuracy: 93.04 %\n",
            "Validation Subclass Accuracy: 58.86 %\n",
            "\n",
            "Epoch 7\n",
            "Training loss: 0.998\n",
            "Validation Loss: 1.701\n",
            "Validation Superclass Accuracy: 93.83 %\n",
            "Validation Subclass Accuracy: 62.50 %\n",
            "\n",
            "Epoch 8\n",
            "Training loss: 0.842\n",
            "Validation Loss: 1.578\n",
            "Validation Superclass Accuracy: 95.09 %\n",
            "Validation Subclass Accuracy: 63.77 %\n",
            "\n",
            "Epoch 9\n",
            "Training loss: 0.753\n",
            "Validation Loss: 1.909\n",
            "Validation Superclass Accuracy: 93.35 %\n",
            "Validation Subclass Accuracy: 61.08 %\n",
            "\n",
            "Epoch 10\n",
            "Training loss: 0.716\n",
            "Validation Loss: 1.625\n",
            "Validation Superclass Accuracy: 93.51 %\n",
            "Validation Subclass Accuracy: 62.34 %\n",
            "\n",
            "Epoch 11\n",
            "Training loss: 0.624\n",
            "Validation Loss: 1.692\n",
            "Validation Superclass Accuracy: 94.78 %\n",
            "Validation Subclass Accuracy: 63.45 %\n",
            "\n",
            "Epoch 12\n",
            "Training loss: 0.581\n",
            "Validation Loss: 1.692\n",
            "Validation Superclass Accuracy: 94.94 %\n",
            "Validation Subclass Accuracy: 65.66 %\n",
            "\n",
            "Epoch 13\n",
            "Training loss: 0.524\n",
            "Validation Loss: 1.659\n",
            "Validation Superclass Accuracy: 94.30 %\n",
            "Validation Subclass Accuracy: 66.30 %\n",
            "\n",
            "Epoch 14\n",
            "Training loss: 0.491\n",
            "Validation Loss: 1.678\n",
            "Validation Superclass Accuracy: 95.09 %\n",
            "Validation Subclass Accuracy: 65.03 %\n",
            "\n",
            "Epoch 15\n",
            "Training loss: 0.467\n",
            "Validation Loss: 1.588\n",
            "Validation Superclass Accuracy: 95.73 %\n",
            "Validation Subclass Accuracy: 67.72 %\n",
            "\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    trainer.train_epoch()\n",
        "    trainer.validate_epoch()\n",
        "    print('')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.eval()\n",
        "if not trainer.test_loader:\n",
        "    raise NotImplementedError('test_loader not specified')\n",
        "\n",
        "superclass_predictions = {'image': [], 'superclass_index': [], 'probs': []}\n",
        "subclass_predictions = {'image': [], 'subclass_index': [], 'probs': []}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(trainer.test_loader):\n",
        "        inputs, img_name = data[0].to(trainer.device), data[1]\n",
        "\n",
        "        if trainer.train_super and trainer.train_sub:\n",
        "            super_outputs, sub_outputs = trainer.model(inputs)\n",
        "        elif trainer.train_super:\n",
        "            super_outputs = trainer.model(inputs)\n",
        "            sub_outputs = None\n",
        "        elif trainer.train_sub:\n",
        "            super_outputs = None\n",
        "            sub_outputs = trainer.model(inputs)\n",
        "        else:\n",
        "            continue  # Skip if neither superclass nor subclass is trained\n",
        "\n",
        "        if trainer.train_super:\n",
        "            super_probs = F.softmax(super_outputs, dim=1)\n",
        "            superclass_predictions['probs'].append(super_probs.cpu().numpy())\n",
        "            superclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "        if trainer.train_sub:\n",
        "            sub_probs = F.softmax(sub_outputs, dim=1)\n",
        "            subclass_predictions['probs'].append(sub_probs.cpu().numpy())\n",
        "            subclass_predictions['image'].append(img_name[0])\n",
        "\n",
        "if trainer.train_super:\n",
        "    superclass_df = pd.DataFrame(data=superclass_predictions)\n",
        "    superclass_df.to_csv('superclass_prediction_with_prob.csv', index=False)\n",
        "\n",
        "if trainer.train_sub:\n",
        "    subclass_df = pd.DataFrame(data=subclass_predictions)\n",
        "    subclass_df.to_csv('subclass_prediction_with_prob.csv', index=False)"
      ],
      "metadata": {
        "id": "bqXKQ8ThL4cV",
        "outputId": "832c5c90-95c7-42c7-8a71-978316d61bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "id": "bqXKQ8ThL4cV",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-e5328e5d2d62>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_super\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0msuperclass_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuperclass_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0msuperclass_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'superclass_prediction_with_prob.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del superclass_predictions(['superclass_index'])"
      ],
      "metadata": {
        "id": "cq7XA-w8g4uV",
        "outputId": "f6445e36-8968-40c4-d12c-1a6546dfc6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "id": "cq7XA-w8g4uV",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-d04f21f15913>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    del superclass_predictions(['superclass_index'])\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot delete function call\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subclass_predictions.keys()"
      ],
      "metadata": {
        "id": "R20p-BELdnOE",
        "outputId": "553e3d3a-0b81-4047-f556-4cc81dfdd3dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "R20p-BELdnOE",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['image', 'subclass_index', 'probs'])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame({'ID': subclass_predictions['image'], 'probs': subclass_predictions['probs']})"
      ],
      "metadata": {
        "id": "X1ABK6LMkoPo"
      },
      "id": "X1ABK6LMkoPo",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv('sub_class_probs.csv', index=False)"
      ],
      "metadata": {
        "id": "AcHVtj1lkzyV"
      },
      "id": "AcHVtj1lkzyV",
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLRAY1PRk2PI"
      },
      "id": "BLRAY1PRk2PI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}